{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ad31d12d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div style=\"text-align: center; background: #2d3748; color: #e2e8f0; padding: 40px; border-radius: 8px;\">\n",
       "    <h1 style=\"color: #cbd5e0; margin-bottom: 30px; font-size: 2.5em;\">Machine translation</h1>\n",
       "    \n",
       "    <div style=\"max-width: 700px; margin: 0 auto; font-size: 16px; line-height: 1.6;\">\n",
       "        <p style=\"margin-bottom: 20px;\">Machine translation (MT) is the study of how to use computers to translate from one language into another. In terms of methodologies MT mainly falls in two categories: rule-based methods and corpus-based-methods.</p>\n",
       "        \n",
       "        <p style=\"margin-bottom: 10px;\">In this short notebook a dataset containing japanese and english text will be loaded and prepared for a machine translation task.</p>\n",
       "        \n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(\"\"\"\n",
    "<div style=\"text-align: center; background: #2d3748; color: #e2e8f0; padding: 40px; border-radius: 8px;\">\n",
    "    <h1 style=\"color: #cbd5e0; margin-bottom: 30px; font-size: 2.5em;\">Machine translation</h1>\n",
    "    \n",
    "    <div style=\"max-width: 700px; margin: 0 auto; font-size: 16px; line-height: 1.6;\">\n",
    "        <p style=\"margin-bottom: 20px;\">Machine translation (MT) is the study of how to use computers to translate from one language into another. In terms of methodologies MT mainly falls in two categories: rule-based methods and corpus-based-methods.</p>\n",
    "        \n",
    "        <p style=\"margin-bottom: 10px;\">In this short notebook a dataset containing japanese and english text will be loaded and prepared for a machine translation task.</p>\n",
    "        \n",
    "    </div>\n",
    "</div>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de185526",
   "metadata": {},
   "source": [
    "# Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e8a6c482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split \n",
    "import tqdm as notebook_tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import utils\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"transformers.modeling_utils\").setLevel(logging.ERROR)\n",
    "\n",
    "from IPython.display import HTML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2a738cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "<div style=\"font-family: Arial, sans-serif; line-height:1.6;\">\n",
       "\n",
       "  <!-- Title -->\n",
       "  <h2 style=\"text-align:center; color:#222;\">Machine Translation (MT) Techniques</h2>\n",
       "\n",
       "  <!-- Root -->\n",
       "  <div style=\"border:2px solid #444; border-radius:10px; padding:15px; width:90%; margin:auto; background-color:#f9f9f9;\">\n",
       "\n",
       "    <h3 style=\"text-align:center; margin:5px 0; color:#333;\">MT Methodologies</h3>\n",
       "\n",
       "    <!-- Categories -->\n",
       "    <div style=\"display:flex; justify-content:space-around; margin-top:20px;\">\n",
       "\n",
       "      <!-- Rule-based -->\n",
       "      <div style=\"flex:1; margin:10px; padding:10px; border:1px solid #999; border-radius:8px; background-color:#d9ecff;\">\n",
       "        <h4 style=\"text-align:center; color:#004080;\">Rule-Based MT (RBMT)</h4>\n",
       "        <p style=\"font-size:14px;\">\n",
       "          • Uses bilingual dictionaries<br>\n",
       "          • Relies on manually written linguistic rules<br>\n",
       "          • Less flexible, resource-intensive\n",
       "        </p>\n",
       "      </div>\n",
       "\n",
       "      <!-- Corpus-based -->\n",
       "      <div style=\"flex:2; margin:10px; padding:10px; border:1px solid #999; border-radius:8px; background-color:#eafbe7;\">\n",
       "        <h4 style=\"text-align:center; color:#006600;\">Corpus-Based MT</h4>\n",
       "\n",
       "        <div style=\"margin-left:10px;\">\n",
       "\n",
       "          <h5 style=\"color:#227700;\">1. Example-Based (EBMT)</h5>\n",
       "          <p style=\"font-size:14px; margin-left:15px;\">\n",
       "            • Translates by retrieving similar sentences from bilingual corpus<br>\n",
       "            • Originated with Nagao (1984)\n",
       "          </p>\n",
       "\n",
       "          <h5 style=\"color:#996600;\">2. Statistical (SMT)</h5>\n",
       "          <p style=\"font-size:14px; margin-left:15px;\">\n",
       "            • Learns translation knowledge automatically from large bilingual data<br>\n",
       "            • Phrase-based, word-based, hierarchical approaches\n",
       "          </p>\n",
       "\n",
       "          <h5 style=\"color:#cc3300;\">3. Neural (NMT)</h5>\n",
       "          <p style=\"font-size:14px; margin-left:15px;\">\n",
       "            • Uses deep learning for sequence-to-sequence translation<br>\n",
       "            • Components: <b>Encoder</b> (semantic representation) and <b>Decoder</b> (generates target)<br>\n",
       "            • Architectures: RNNs (LSTM/GRU), currently Transformer-based<br>\n",
       "            • No manually encoded rules\n",
       "          </p>\n",
       "\n",
       "        </div>\n",
       "      </div>\n",
       "    </div>\n",
       "  </div>\n",
       "</div>\n",
       "</html>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<div style=\"font-family: Arial, sans-serif; line-height:1.6;\">\n",
    "\n",
    "  <!-- Title -->\n",
    "  <h2 style=\"text-align:center; color:#222;\">Machine Translation (MT) Techniques</h2>\n",
    "\n",
    "  <!-- Root -->\n",
    "  <div style=\"border:2px solid #444; border-radius:10px; padding:15px; width:90%; margin:auto; background-color:#f9f9f9;\">\n",
    "\n",
    "    <h3 style=\"text-align:center; margin:5px 0; color:#333;\">MT Methodologies</h3>\n",
    "\n",
    "    <!-- Categories -->\n",
    "    <div style=\"display:flex; justify-content:space-around; margin-top:20px;\">\n",
    "\n",
    "      <!-- Rule-based -->\n",
    "      <div style=\"flex:1; margin:10px; padding:10px; border:1px solid #999; border-radius:8px; background-color:#d9ecff;\">\n",
    "        <h4 style=\"text-align:center; color:#004080;\">Rule-Based MT (RBMT)</h4>\n",
    "        <p style=\"font-size:14px;\">\n",
    "          • Uses bilingual dictionaries<br>\n",
    "          • Relies on manually written linguistic rules<br>\n",
    "          • Less flexible, resource-intensive\n",
    "        </p>\n",
    "      </div>\n",
    "\n",
    "      <!-- Corpus-based -->\n",
    "      <div style=\"flex:2; margin:10px; padding:10px; border:1px solid #999; border-radius:8px; background-color:#eafbe7;\">\n",
    "        <h4 style=\"text-align:center; color:#006600;\">Corpus-Based MT</h4>\n",
    "\n",
    "        <div style=\"margin-left:10px;\">\n",
    "\n",
    "          <h5 style=\"color:#227700;\">1. Example-Based (EBMT)</h5>\n",
    "          <p style=\"font-size:14px; margin-left:15px;\">\n",
    "            • Translates by retrieving similar sentences from bilingual corpus<br>\n",
    "            • Originated with Nagao (1984)\n",
    "          </p>\n",
    "\n",
    "          <h5 style=\"color:#996600;\">2. Statistical (SMT)</h5>\n",
    "          <p style=\"font-size:14px; margin-left:15px;\">\n",
    "            • Learns translation knowledge automatically from large bilingual data<br>\n",
    "            • Phrase-based, word-based, hierarchical approaches\n",
    "          </p>\n",
    "\n",
    "          <h5 style=\"color:#cc3300;\">3. Neural (NMT)</h5>\n",
    "          <p style=\"font-size:14px; margin-left:15px;\">\n",
    "            • Uses deep learning for sequence-to-sequence translation<br>\n",
    "            • Components: <b>Encoder</b> (semantic representation) and <b>Decoder</b> (generates target)<br>\n",
    "            • Architectures: RNNs (LSTM/GRU), currently Transformer-based<br>\n",
    "            • No manually encoded rules\n",
    "          </p>\n",
    "\n",
    "        </div>\n",
    "      </div>\n",
    "    </div>\n",
    "  </div>\n",
    "</div>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "from IPython.display import HTML\n",
    "HTML(html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021eda5b",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "788c26dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laran\\.cache\\kagglehub\\datasets\\team-ai\\japaneseenglish-bilingual-corpus\\versions\\3\n"
     ]
    }
   ],
   "source": [
    "# Download latest version\n",
    "root=Path(kagglehub.dataset_download(\"team-ai/japaneseenglish-bilingual-corpus\"))\n",
    "print(root)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314aa4f9",
   "metadata": {},
   "source": [
    "Source of the data: https://www.kaggle.com/datasets/team-ai/japaneseenglish-bilingual-corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "483c0b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WindowsPath('C:/Users/laran/.cache/kagglehub/datasets/team-ai/japaneseenglish-bilingual-corpus/versions/3/BDS00389.xml'),\n",
      " WindowsPath('C:/Users/laran/.cache/kagglehub/datasets/team-ai/japaneseenglish-bilingual-corpus/versions/3/fonts-japanese-gothic.ttf'),\n",
      " WindowsPath('C:/Users/laran/.cache/kagglehub/datasets/team-ai/japaneseenglish-bilingual-corpus/versions/3/kyoto_lexicon.csv'),\n",
      " WindowsPath('C:/Users/laran/.cache/kagglehub/datasets/team-ai/japaneseenglish-bilingual-corpus/versions/3/readme.pdf'),\n",
      " WindowsPath('C:/Users/laran/.cache/kagglehub/datasets/team-ai/japaneseenglish-bilingual-corpus/versions/3/wiki_corpus_2.01/BDS/BDS00001.xml'),\n",
      " WindowsPath('C:/Users/laran/.cache/kagglehub/datasets/team-ai/japaneseenglish-bilingual-corpus/versions/3/wiki_corpus_2.01/BDS/BDS00002.xml'),\n",
      " WindowsPath('C:/Users/laran/.cache/kagglehub/datasets/team-ai/japaneseenglish-bilingual-corpus/versions/3/wiki_corpus_2.01/BDS/BDS00003.xml'),\n",
      " WindowsPath('C:/Users/laran/.cache/kagglehub/datasets/team-ai/japaneseenglish-bilingual-corpus/versions/3/wiki_corpus_2.01/BDS/BDS00004.xml'),\n",
      " WindowsPath('C:/Users/laran/.cache/kagglehub/datasets/team-ai/japaneseenglish-bilingual-corpus/versions/3/wiki_corpus_2.01/BDS/BDS00005.xml'),\n",
      " WindowsPath('C:/Users/laran/.cache/kagglehub/datasets/team-ai/japaneseenglish-bilingual-corpus/versions/3/wiki_corpus_2.01/BDS/BDS00006.xml')]\n"
     ]
    }
   ],
   "source": [
    "files=sorted(p for p in root.rglob(\"*\") if p.is_file())\n",
    "pprint(files[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dec28ad",
   "metadata": {},
   "source": [
    "Files are mostly XML files, to be able to use the parallel english / japanese text the XML files must be parsed first: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32171a0a",
   "metadata": {},
   "source": [
    "### 1) check the tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dda9756b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "art {'orl': 'ja', 'trl': 'en'}\n"
     ]
    }
   ],
   "source": [
    "base = root / \"wiki_corpus_2.01\" / \"BDS\"\n",
    "xml_file = sorted(base.glob(\"BDS*.xml\"))[0]\n",
    "root = ET.parse(xml_file).getroot()\n",
    "\n",
    "for el in root.iter():\n",
    "    print(el.tag, el.attrib)\n",
    "    # Stop early to avoid printing everything\n",
    "    if len(list(el)) > 0:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b02780",
   "metadata": {},
   "source": [
    "Tags are 'ja' for japanese and 'en' for english.  \n",
    "The structure will be further explored to properly extract japanese - english pairs\n",
    "\n",
    "### 2. inspect the structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "366a9fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level-1 child tags: Counter({'sec': 6, 'par': 5, 'inf': 1, 'tit': 1, 'copyright': 1})\n",
      "\n",
      "<inf> children: Counter()\n",
      "  sample leaf <inf>: jawiki-20080607-pages-articles.xml\n",
      "\n",
      "<tit> children: Counter({'e': 3, 'cmt': 3, 'j': 1})\n",
      "  sample leaf <j>: 雪舟\n",
      "\n",
      "<par> children: Counter({'sen': 2})\n",
      "  sample leaf <j>: 雪舟（せっしゅう、1420年（応永27年） - 1506年（永正3年））は号で、15世紀後半室町時代に活躍した水墨画家・禅僧で、画聖とも称えられる。\n",
      "\n",
      "<sec> children: Counter({'par': 3, 'tit': 1})\n",
      "  sample leaf <j>: 生涯\n",
      "\n",
      "<copyright> children: Counter()\n",
      "  sample leaf <copyright>: copyright (c) 2010 Avanzare(id:34657), Kanejan(id:78613), Tommy6(id:51773), Nnh(id:474), Suguri F(id:11127), FREEZA(id:6\n"
     ]
    }
   ],
   "source": [
    "assert root.tag.endswith(\"art\") and root.attrib.get(\"orl\")==\"ja\" and root.attrib.get(\"trl\")==\"en\"\n",
    "\n",
    "# List first-level children under <art>\n",
    "lvl1 = [c.tag for c in root]\n",
    "\n",
    "print(\"Level-1 child tags:\", Counter(lvl1))\n",
    "\n",
    "# Peek deeper: for each distinct lvl1 tag, show its distinct children and sample text\n",
    "def strip_ns(tag): \n",
    "    return tag.split(\"}\",1)[1] if \"}\" in tag else tag\n",
    "\n",
    "seen = set()\n",
    "for c in root:\n",
    "    t = strip_ns(c.tag)\n",
    "    if t in seen: \n",
    "        continue\n",
    "    seen.add(t)\n",
    "    sub = [strip_ns(x.tag) for x in list(c)]\n",
    "    print(f\"\\n<{t}> children:\", Counter(sub))\n",
    "    # print a couple of leaf texts\n",
    "    for leaf in c.iter():\n",
    "        if len(list(leaf))==0 and (leaf.text or \"\").strip():\n",
    "            txt = leaf.text.strip().replace(\"\\n\",\" \")[:120]\n",
    "            print(f\"  sample leaf <{strip_ns(leaf.tag)}>: {txt}\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b886d636",
   "metadata": {},
   "source": [
    "**interpretation**: \n",
    "- Root is: <art orl=\"ja\" trl=\"en\">\n",
    "- frequent childrens are: sec, par, tit, inf, copyright\n",
    "- language tags are: < j > for japanese and < e > for english \n",
    "\n",
    "\n",
    "With these informations we can built the extractor. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04eb13a",
   "metadata": {},
   "source": [
    "### 3) Built the extractor and the paired dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dce48e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base = root / \"wiki_corpus_2.01\" / \"BDS\"\n",
    "base.glob(\"BDS*.xml\")\n",
    "\n",
    "TAG_PAIR      = None         # No wrapper available\n",
    "TAG_ORIGINAL  = \"j\"          # japanese tag\n",
    "TAG_TRANSL    = \"e\"          # english tag\n",
    "\n",
    "def strip_ns(tag):\n",
    "    return tag.split(\"}\",1)[1] if \"}\" in tag else tag\n",
    "\n",
    "def text_or_none(el):\n",
    "    return (el.text or \"\").strip() if el is not None and el.text else None\n",
    "\n",
    "pairs = []\n",
    "for xf in sorted(base.glob(\"BDS*.xml\")):\n",
    "    root = ET.parse(xf).getroot()\n",
    "\n",
    "    if TAG_PAIR:\n",
    "        # option 1 --> if I have the wrapper (not our case as TAG_PAIR=None)\n",
    "        for node in root.findall(f\".//{TAG_PAIR}\"):\n",
    "            ja = text_or_none(node.find(TAG_ORIGINAL))\n",
    "            en = text_or_none(node.find(TAG_TRANSL))\n",
    "            if ja and en:\n",
    "                pairs.append((ja, en))\n",
    "    else:\n",
    "        # option 2 --> called in case we have no explicit wrapper (our case)\n",
    "        for node in root.iter():\n",
    "            children = list(node)\n",
    "            if not children: \n",
    "                continue\n",
    "            tagmap = {strip_ns(c.tag).lower(): c for c in children}\n",
    "            if TAG_ORIGINAL.lower() in tagmap and TAG_TRANSL.lower() in tagmap:\n",
    "                ja = text_or_none(tagmap[TAG_ORIGINAL.lower()])\n",
    "                en = text_or_none(tagmap[TAG_TRANSL.lower()])\n",
    "                if ja and en:\n",
    "                    pairs.append((ja, en))\n",
    "\n",
    "df = pd.DataFrame(pairs, columns=[\"ja\", \"en\"]).dropna()   # dataframe and cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7df31f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".xml-container {\n",
       "    max-width: 1000px;\n",
       "    margin: 20px auto;\n",
       "    padding: 30px;\n",
       "    background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);\n",
       "    border-radius: 16px;\n",
       "    box-shadow: 0 10px 30px rgba(0,0,0,0.1);\n",
       "    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
       "    position: relative;\n",
       "    overflow: hidden;\n",
       "}\n",
       "\n",
       ".xml-container::before {\n",
       "    content: '';\n",
       "    position: absolute;\n",
       "    top: 0;\n",
       "    left: 0;\n",
       "    right: 0;\n",
       "    bottom: 0;\n",
       "    background: url('data:image/svg+xml,<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 100 100\"><circle cx=\"25\" cy=\"25\" r=\"1\" fill=\"rgba(255,255,255,0.3)\"/><circle cx=\"75\" cy=\"75\" r=\"1.5\" fill=\"rgba(255,255,255,0.2)\"/><circle cx=\"50\" cy=\"10\" r=\"0.8\" fill=\"rgba(255,255,255,0.4)\"/></svg>') repeat;\n",
       "    pointer-events: none;\n",
       "}\n",
       "\n",
       ".header {\n",
       "    text-align: center;\n",
       "    margin-bottom: 25px;\n",
       "    position: relative;\n",
       "    z-index: 2;\n",
       "}\n",
       "\n",
       ".main-title {\n",
       "    font-size: 2.2em;\n",
       "    font-weight: 700;\n",
       "    margin: 0;\n",
       "    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
       "    -webkit-background-clip: text;\n",
       "    -webkit-text-fill-color: transparent;\n",
       "    background-clip: text;\n",
       "    text-shadow: 0 2px 4px rgba(0,0,0,0.1);\n",
       "}\n",
       "\n",
       ".legend {\n",
       "    display: flex;\n",
       "    gap: 15px;\n",
       "    justify-content: center;\n",
       "    margin: 20px 0;\n",
       "    flex-wrap: wrap;\n",
       "    position: relative;\n",
       "    z-index: 2;\n",
       "}\n",
       "\n",
       ".legend-item {\n",
       "    background: rgba(255, 255, 255, 0.9);\n",
       "    backdrop-filter: blur(10px);\n",
       "    padding: 8px 16px;\n",
       "    border-radius: 20px;\n",
       "    font-size: 0.9em;\n",
       "    font-weight: 500;\n",
       "    box-shadow: 0 2px 8px rgba(0,0,0,0.1);\n",
       "    border: 1px solid rgba(255,255,255,0.2);\n",
       "    transition: all 0.3s ease;\n",
       "}\n",
       "\n",
       ".legend-item:hover {\n",
       "    transform: translateY(-2px);\n",
       "    box-shadow: 0 4px 12px rgba(0,0,0,0.15);\n",
       "}\n",
       "\n",
       ".data-source { background: linear-gradient(135deg, #e3f2fd, #bbdefb); color: #1565c0; }\n",
       ".xml-nodes { background: linear-gradient(135deg, #f3e5f5, #e1bee7); color: #7b1fa2; }\n",
       ".traversal { background: linear-gradient(135deg, #e8f5e8, #c8e6c9); color: #2e7d32; }\n",
       ".output { background: linear-gradient(135deg, #fff8e1, #ffecb3); color: #f57c00; }\n",
       "\n",
       ".flowchart-container {\n",
       "    background: rgba(255, 255, 255, 0.95);\n",
       "    backdrop-filter: blur(15px);\n",
       "    border-radius: 12px;\n",
       "    padding: 25px;\n",
       "    margin: 20px 0;\n",
       "    box-shadow: 0 8px 25px rgba(0,0,0,0.1);\n",
       "    border: 1px solid rgba(255,255,255,0.3);\n",
       "    position: relative;\n",
       "    z-index: 2;\n",
       "}\n",
       "\n",
       ".flowchart-svg {\n",
       "    width: 100%;\n",
       "    height: auto;\n",
       "    max-width: 950px;\n",
       "    display: block;\n",
       "    margin: 0 auto;\n",
       "}\n",
       "\n",
       ".notes-section {\n",
       "    background: rgba(255, 255, 255, 0.9);\n",
       "    backdrop-filter: blur(10px);\n",
       "    border-radius: 12px;\n",
       "    padding: 20px;\n",
       "    margin-top: 20px;\n",
       "    border-left: 4px solid #667eea;\n",
       "    position: relative;\n",
       "    z-index: 2;\n",
       "}\n",
       "\n",
       ".notes-title {\n",
       "    font-size: 1.2em;\n",
       "    font-weight: 600;\n",
       "    color: #2c3e50;\n",
       "    margin: 0 0 15px 0;\n",
       "}\n",
       "\n",
       ".notes-list {\n",
       "    margin: 0;\n",
       "    padding-left: 20px;\n",
       "    color: #34495e;\n",
       "    line-height: 1.6;\n",
       "}\n",
       "\n",
       ".notes-list li {\n",
       "    margin-bottom: 8px;\n",
       "    position: relative;\n",
       "}\n",
       "\n",
       ".notes-list code {\n",
       "    background: rgba(103, 126, 234, 0.1);\n",
       "    padding: 2px 6px;\n",
       "    border-radius: 4px;\n",
       "    font-family: 'Consolas', 'Monaco', monospace;\n",
       "    font-size: 0.9em;\n",
       "    color: #667eea;\n",
       "}\n",
       "\n",
       "@media (max-width: 768px) {\n",
       "    .xml-container {\n",
       "        margin: 10px;\n",
       "        padding: 20px;\n",
       "    }\n",
       "    \n",
       "    .main-title {\n",
       "        font-size: 1.8em;\n",
       "    }\n",
       "    \n",
       "    .legend {\n",
       "        gap: 10px;\n",
       "    }\n",
       "    \n",
       "    .legend-item {\n",
       "        padding: 6px 12px;\n",
       "        font-size: 0.8em;\n",
       "    }\n",
       "    \n",
       "    .flowchart-container {\n",
       "        padding: 15px;\n",
       "    }\n",
       "}\n",
       "</style>\n",
       "\n",
       "<div class=\"xml-container\">\n",
       "    <div class=\"header\">\n",
       "        <h1 class=\"main-title\">XML Structure & Pair Extraction</h1>\n",
       "        <p style=\"color: #7f8c8d; font-size: 1.1em; margin: 5px 0 0 0;\">Advanced Schematic Visualization</p>\n",
       "    </div>\n",
       "\n",
       "    <div class=\"legend\">\n",
       "        <div class=\"legend-item data-source\">📁 Data Source</div>\n",
       "        <div class=\"legend-item xml-nodes\">🏷️ XML Nodes</div>\n",
       "        <div class=\"legend-item traversal\">🔄 Traversal Logic</div>\n",
       "        <div class=\"legend-item output\">📋 Output</div>\n",
       "    </div>\n",
       "\n",
       "    <div class=\"flowchart-container\">\n",
       "        <svg class=\"flowchart-svg\" viewBox=\"0 0 950 550\" role=\"img\" aria-label=\"Enhanced flowchart of XML parsing and bilingual pair extraction\">\n",
       "            <defs>\n",
       "                <marker id=\"arrow\" viewBox=\"0 0 12 12\" refX=\"10\" refY=\"6\" markerWidth=\"10\" markerHeight=\"10\" orient=\"auto-start-reverse\">\n",
       "                    <path d=\"M 2 2 L 10 6 L 2 10 z\" fill=\"#4a5568\" stroke=\"#4a5568\" stroke-width=\"1\"/>\n",
       "                </marker>\n",
       "                \n",
       "                <linearGradient id=\"dataGradient\" x1=\"0%\" y1=\"0%\" x2=\"100%\" y2=\"100%\">\n",
       "                    <stop offset=\"0%\" style=\"stop-color:#e3f2fd;stop-opacity:1\" />\n",
       "                    <stop offset=\"100%\" style=\"stop-color:#bbdefb;stop-opacity:1\" />\n",
       "                </linearGradient>\n",
       "                \n",
       "                <linearGradient id=\"xmlGradient\" x1=\"0%\" y1=\"0%\" x2=\"100%\" y2=\"100%\">\n",
       "                    <stop offset=\"0%\" style=\"stop-color:#f3e5f5;stop-opacity:1\" />\n",
       "                    <stop offset=\"100%\" style=\"stop-color:#e1bee7;stop-opacity:1\" />\n",
       "                </linearGradient>\n",
       "                \n",
       "                <linearGradient id=\"traversalGradient\" x1=\"0%\" y1=\"0%\" x2=\"100%\" y2=\"100%\">\n",
       "                    <stop offset=\"0%\" style=\"stop-color:#e8f5e8;stop-opacity:1\" />\n",
       "                    <stop offset=\"100%\" style=\"stop-color:#c8e6c9;stop-opacity:1\" />\n",
       "                </linearGradient>\n",
       "                \n",
       "                <linearGradient id=\"outputGradient\" x1=\"0%\" y1=\"0%\" x2=\"100%\" y2=\"100%\">\n",
       "                    <stop offset=\"0%\" style=\"stop-color:#fff8e1;stop-opacity:1\" />\n",
       "                    <stop offset=\"100%\" style=\"stop-color:#ffecb3;stop-opacity:1\" />\n",
       "                </linearGradient>\n",
       "                \n",
       "                <filter id=\"shadow\" x=\"-20%\" y=\"-20%\" width=\"140%\" height=\"140%\">\n",
       "                    <feDropShadow dx=\"2\" dy=\"4\" stdDeviation=\"3\" flood-color=\"rgba(0,0,0,0.2)\"/>\n",
       "                </filter>\n",
       "            </defs>\n",
       "\n",
       "            <!-- Enhanced Boxes with gradients and shadows -->\n",
       "            <!-- Data source -->\n",
       "            <rect x=\"30\" y=\"30\" rx=\"12\" ry=\"12\" width=\"260\" height=\"80\" fill=\"url(#dataGradient)\" stroke=\"#90caf9\" stroke-width=\"2\" filter=\"url(#shadow)\"/>\n",
       "            <text x=\"160\" y=\"58\" text-anchor=\"middle\" font-size=\"16\" font-weight=\"600\" fill=\"#1565c0\">📁 Filesystem</text>\n",
       "            <text x=\"160\" y=\"78\" text-anchor=\"middle\" font-size=\"13\" fill=\"#1976d2\">base.glob(\"BDS*.xml\") → BDS*.xml</text>\n",
       "\n",
       "            <!-- Parse -->\n",
       "            <rect x=\"340\" y=\"30\" rx=\"12\" ry=\"12\" width=\"260\" height=\"80\" fill=\"url(#traversalGradient)\" stroke=\"#81c784\" stroke-width=\"2\" filter=\"url(#shadow)\"/>\n",
       "            <text x=\"470\" y=\"58\" text-anchor=\"middle\" font-size=\"16\" font-weight=\"600\" fill=\"#2e7d32\">🔍 Parse XML</text>\n",
       "            <text x=\"470\" y=\"78\" text-anchor=\"middle\" font-size=\"13\" fill=\"#388e3c\">ET.parse(xf).getroot()</text>\n",
       "\n",
       "            <!-- Root art -->\n",
       "            <rect x=\"650\" y=\"20\" rx=\"12\" ry=\"12\" width=\"260\" height=\"100\" fill=\"url(#xmlGradient)\" stroke=\"#ba68c8\" stroke-width=\"2\" filter=\"url(#shadow)\"/>\n",
       "            <text x=\"780\" y=\"50\" text-anchor=\"middle\" font-size=\"16\" font-weight=\"600\" fill=\"#7b1fa2\">🏷️ &lt;art&gt; (root)</text>\n",
       "            <text x=\"780\" y=\"70\" text-anchor=\"middle\" font-size=\"13\" fill=\"#8e24aa\">Attributes:</text>\n",
       "            <text x=\"780\" y=\"88\" text-anchor=\"middle\" font-size=\"13\" fill=\"#8e24aa\">orl=\"ja\", trl=\"en\"</text>\n",
       "\n",
       "            <!-- First level children -->\n",
       "            <rect x=\"80\" y=\"160\" rx=\"12\" ry=\"12\" width=\"320\" height=\"130\" fill=\"url(#xmlGradient)\" stroke=\"#ba68c8\" stroke-width=\"2\" filter=\"url(#shadow)\"/>\n",
       "            <text x=\"240\" y=\"185\" text-anchor=\"middle\" font-size=\"16\" font-weight=\"600\" fill=\"#7b1fa2\">📊 Level-1 Children</text>\n",
       "            <text x=\"240\" y=\"208\" text-anchor=\"middle\" font-size=\"13\" fill=\"#8e24aa\">for c in root → Counter([c.tag])</text>\n",
       "            <text x=\"240\" y=\"228\" text-anchor=\"middle\" font-size=\"13\" fill=\"#8e24aa\">strip_ns(tag) removes namespaces</text>\n",
       "            <text x=\"240\" y=\"248\" text-anchor=\"middle\" font-size=\"13\" fill=\"#8e24aa\">Prepares for sibling analysis</text>\n",
       "\n",
       "            <!-- Traversal logic -->\n",
       "            <rect x=\"460\" y=\"160\" rx=\"12\" ry=\"12\" width=\"380\" height=\"150\" fill=\"url(#traversalGradient)\" stroke=\"#81c784\" stroke-width=\"2\" filter=\"url(#shadow)\"/>\n",
       "            <text x=\"650\" y=\"185\" text-anchor=\"middle\" font-size=\"16\" font-weight=\"600\" fill=\"#2e7d32\">🔄 Sibling Lookup Logic</text>\n",
       "            <text x=\"650\" y=\"208\" text-anchor=\"middle\" font-size=\"12\" fill=\"#388e3c\">TAG_PAIR = None; TAG_ORIGINAL=\"j\"; TAG_TRANSL=\"e\"</text>\n",
       "            <text x=\"650\" y=\"228\" text-anchor=\"middle\" font-size=\"12\" fill=\"#388e3c\">For each node with children:</text>\n",
       "            <text x=\"650\" y=\"248\" text-anchor=\"middle\" font-size=\"12\" fill=\"#388e3c\">tagmap = { strip_ns(child.tag).lower(): child }</text>\n",
       "            <text x=\"650\" y=\"268\" text-anchor=\"middle\" font-size=\"12\" fill=\"#388e3c\">If \"j\" in tagmap and \"e\" in tagmap → extract texts</text>\n",
       "\n",
       "            <!-- Node with j/e -->\n",
       "            <rect x=\"120\" y=\"340\" rx=\"12\" ry=\"12\" width=\"330\" height=\"170\" fill=\"url(#xmlGradient)\" stroke=\"#ba68c8\" stroke-width=\"2\" filter=\"url(#shadow)\"/>\n",
       "            <text x=\"285\" y=\"365\" text-anchor=\"middle\" font-size=\"16\" font-weight=\"600\" fill=\"#7b1fa2\">🎯 Target Node Structure</text>\n",
       "\n",
       "            <rect x=\"150\" y=\"385\" rx=\"8\" ry=\"8\" width=\"130\" height=\"45\" fill=\"rgba(255,255,255,0.8)\" stroke=\"#ba68c8\" stroke-width=\"1.5\"/>\n",
       "            <text x=\"215\" y=\"410\" text-anchor=\"middle\" font-size=\"14\" font-weight=\"500\" fill=\"#7b1fa2\">&lt;j&gt; 日本語</text>\n",
       "\n",
       "            <rect x=\"290\" y=\"385\" rx=\"8\" ry=\"8\" width=\"130\" height=\"45\" fill=\"rgba(255,255,255,0.8)\" stroke=\"#ba68c8\" stroke-width=\"1.5\"/>\n",
       "            <text x=\"355\" y=\"410\" text-anchor=\"middle\" font-size=\"14\" font-weight=\"500\" fill=\"#7b1fa2\">&lt;e&gt; English</text>\n",
       "\n",
       "            <text x=\"285\" y=\"455\" text-anchor=\"middle\" font-size=\"12\" fill=\"#8e24aa\">text_or_none(el) trims and guards None</text>\n",
       "            <text x=\"285\" y=\"475\" text-anchor=\"middle\" font-size=\"12\" fill=\"#8e24aa\">Ensures clean text extraction</text>\n",
       "\n",
       "            <!-- Output pairs -->\n",
       "            <rect x=\"530\" y=\"350\" rx=\"12\" ry=\"12\" width=\"330\" height=\"140\" fill=\"url(#outputGradient)\" stroke=\"#ffb74d\" stroke-width=\"2\" filter=\"url(#shadow)\"/>\n",
       "            <text x=\"695\" y=\"375\" text-anchor=\"middle\" font-size=\"16\" font-weight=\"600\" fill=\"#f57c00\">📋 Output Pairs</text>\n",
       "            <text x=\"695\" y=\"398\" text-anchor=\"middle\" font-size=\"14\" fill=\"#ff9800\">List[Tuple[str, str]]</text>\n",
       "            <text x=\"695\" y=\"420\" text-anchor=\"middle\" font-size=\"13\" fill=\"#ff9800\">Append (ja, en) if both non-empty</text>\n",
       "            <text x=\"695\" y=\"440\" text-anchor=\"middle\" font-size=\"13\" fill=\"#ff9800\">pairs.append((ja, en))</text>\n",
       "            <text x=\"695\" y=\"460\" text-anchor=\"middle\" font-size=\"13\" fill=\"#ff9800\">Quality-filtered bilingual data</text>\n",
       "\n",
       "            <!-- Enhanced Arrows with better styling -->\n",
       "            <line x1=\"290\" y1=\"70\" x2=\"340\" y2=\"70\" stroke=\"#4a5568\" stroke-width=\"3\" marker-end=\"url(#arrow)\"/>\n",
       "            <line x1=\"600\" y1=\"70\" x2=\"650\" y2=\"70\" stroke=\"#4a5568\" stroke-width=\"3\" marker-end=\"url(#arrow)\"/>\n",
       "            <line x1=\"750\" y1=\"120\" x2=\"400\" y2=\"160\" stroke=\"#4a5568\" stroke-width=\"3\" marker-end=\"url(#arrow)\"/>\n",
       "            <line x1=\"400\" y1=\"225\" x2=\"460\" y2=\"235\" stroke=\"#4a5568\" stroke-width=\"3\" marker-end=\"url(#arrow)\"/>\n",
       "            <line x1=\"580\" y1=\"310\" x2=\"350\" y2=\"340\" stroke=\"#4a5568\" stroke-width=\"3\" marker-end=\"url(#arrow)\"/>\n",
       "            <line x1=\"450\" y1=\"420\" x2=\"530\" y2=\"420\" stroke=\"#4a5568\" stroke-width=\"3\" marker-end=\"url(#arrow)\"/>\n",
       "        </svg>\n",
       "    </div>\n",
       "\n",
       "    <div class=\"notes-section\">\n",
       "        <h3 class=\"notes-title\">💡 Implementation Details</h3>\n",
       "        <ul class=\"notes-list\">\n",
       "            <li><code>root.tag.endswith(\"art\")</code> and attribute validation ensure input conformity to <code>&lt;art orl=\"ja\" trl=\"en\"&gt;</code> schema.</li>\n",
       "            <li>When <code>TAG_PAIR is None</code>, the algorithm bypasses wrapper tags and directly scans nodes containing both <code>&lt;j&gt;</code> and <code>&lt;e&gt;</code> children.</li>\n",
       "            <li><code>strip_ns</code> function normalizes XML namespaces before comparison; all tag matching is case-insensitive.</li>\n",
       "            <li>Text extraction uses <code>text_or_none</code> with trimming and null guards—only non-empty content enters the final pairs collection.</li>\n",
       "            <li>The traversal algorithm scales efficiently across large XML documents with nested bilingual content structures.</li>\n",
       "        </ul>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<style>\n",
    ".xml-container {\n",
    "    max-width: 1000px;\n",
    "    margin: 20px auto;\n",
    "    padding: 30px;\n",
    "    background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);\n",
    "    border-radius: 16px;\n",
    "    box-shadow: 0 10px 30px rgba(0,0,0,0.1);\n",
    "    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
    "    position: relative;\n",
    "    overflow: hidden;\n",
    "}\n",
    "\n",
    ".xml-container::before {\n",
    "    content: '';\n",
    "    position: absolute;\n",
    "    top: 0;\n",
    "    left: 0;\n",
    "    right: 0;\n",
    "    bottom: 0;\n",
    "    background: url('data:image/svg+xml,<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 100 100\"><circle cx=\"25\" cy=\"25\" r=\"1\" fill=\"rgba(255,255,255,0.3)\"/><circle cx=\"75\" cy=\"75\" r=\"1.5\" fill=\"rgba(255,255,255,0.2)\"/><circle cx=\"50\" cy=\"10\" r=\"0.8\" fill=\"rgba(255,255,255,0.4)\"/></svg>') repeat;\n",
    "    pointer-events: none;\n",
    "}\n",
    "\n",
    ".header {\n",
    "    text-align: center;\n",
    "    margin-bottom: 25px;\n",
    "    position: relative;\n",
    "    z-index: 2;\n",
    "}\n",
    "\n",
    ".main-title {\n",
    "    font-size: 2.2em;\n",
    "    font-weight: 700;\n",
    "    margin: 0;\n",
    "    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "    -webkit-background-clip: text;\n",
    "    -webkit-text-fill-color: transparent;\n",
    "    background-clip: text;\n",
    "    text-shadow: 0 2px 4px rgba(0,0,0,0.1);\n",
    "}\n",
    "\n",
    ".legend {\n",
    "    display: flex;\n",
    "    gap: 15px;\n",
    "    justify-content: center;\n",
    "    margin: 20px 0;\n",
    "    flex-wrap: wrap;\n",
    "    position: relative;\n",
    "    z-index: 2;\n",
    "}\n",
    "\n",
    ".legend-item {\n",
    "    background: rgba(255, 255, 255, 0.9);\n",
    "    backdrop-filter: blur(10px);\n",
    "    padding: 8px 16px;\n",
    "    border-radius: 20px;\n",
    "    font-size: 0.9em;\n",
    "    font-weight: 500;\n",
    "    box-shadow: 0 2px 8px rgba(0,0,0,0.1);\n",
    "    border: 1px solid rgba(255,255,255,0.2);\n",
    "    transition: all 0.3s ease;\n",
    "}\n",
    "\n",
    ".legend-item:hover {\n",
    "    transform: translateY(-2px);\n",
    "    box-shadow: 0 4px 12px rgba(0,0,0,0.15);\n",
    "}\n",
    "\n",
    ".data-source { background: linear-gradient(135deg, #e3f2fd, #bbdefb); color: #1565c0; }\n",
    ".xml-nodes { background: linear-gradient(135deg, #f3e5f5, #e1bee7); color: #7b1fa2; }\n",
    ".traversal { background: linear-gradient(135deg, #e8f5e8, #c8e6c9); color: #2e7d32; }\n",
    ".output { background: linear-gradient(135deg, #fff8e1, #ffecb3); color: #f57c00; }\n",
    "\n",
    ".flowchart-container {\n",
    "    background: rgba(255, 255, 255, 0.95);\n",
    "    backdrop-filter: blur(15px);\n",
    "    border-radius: 12px;\n",
    "    padding: 25px;\n",
    "    margin: 20px 0;\n",
    "    box-shadow: 0 8px 25px rgba(0,0,0,0.1);\n",
    "    border: 1px solid rgba(255,255,255,0.3);\n",
    "    position: relative;\n",
    "    z-index: 2;\n",
    "}\n",
    "\n",
    ".flowchart-svg {\n",
    "    width: 100%;\n",
    "    height: auto;\n",
    "    max-width: 950px;\n",
    "    display: block;\n",
    "    margin: 0 auto;\n",
    "}\n",
    "\n",
    ".notes-section {\n",
    "    background: rgba(255, 255, 255, 0.9);\n",
    "    backdrop-filter: blur(10px);\n",
    "    border-radius: 12px;\n",
    "    padding: 20px;\n",
    "    margin-top: 20px;\n",
    "    border-left: 4px solid #667eea;\n",
    "    position: relative;\n",
    "    z-index: 2;\n",
    "}\n",
    "\n",
    ".notes-title {\n",
    "    font-size: 1.2em;\n",
    "    font-weight: 600;\n",
    "    color: #2c3e50;\n",
    "    margin: 0 0 15px 0;\n",
    "}\n",
    "\n",
    ".notes-list {\n",
    "    margin: 0;\n",
    "    padding-left: 20px;\n",
    "    color: #34495e;\n",
    "    line-height: 1.6;\n",
    "}\n",
    "\n",
    ".notes-list li {\n",
    "    margin-bottom: 8px;\n",
    "    position: relative;\n",
    "}\n",
    "\n",
    ".notes-list code {\n",
    "    background: rgba(103, 126, 234, 0.1);\n",
    "    padding: 2px 6px;\n",
    "    border-radius: 4px;\n",
    "    font-family: 'Consolas', 'Monaco', monospace;\n",
    "    font-size: 0.9em;\n",
    "    color: #667eea;\n",
    "}\n",
    "\n",
    "@media (max-width: 768px) {\n",
    "    .xml-container {\n",
    "        margin: 10px;\n",
    "        padding: 20px;\n",
    "    }\n",
    "    \n",
    "    .main-title {\n",
    "        font-size: 1.8em;\n",
    "    }\n",
    "    \n",
    "    .legend {\n",
    "        gap: 10px;\n",
    "    }\n",
    "    \n",
    "    .legend-item {\n",
    "        padding: 6px 12px;\n",
    "        font-size: 0.8em;\n",
    "    }\n",
    "    \n",
    "    .flowchart-container {\n",
    "        padding: 15px;\n",
    "    }\n",
    "}\n",
    "</style>\n",
    "\n",
    "<div class=\"xml-container\">\n",
    "    <div class=\"header\">\n",
    "        <h1 class=\"main-title\">XML Structure & Pair Extraction</h1>\n",
    "        <p style=\"color: #7f8c8d; font-size: 1.1em; margin: 5px 0 0 0;\">Advanced Schematic Visualization</p>\n",
    "    </div>\n",
    "\n",
    "    <div class=\"legend\">\n",
    "        <div class=\"legend-item data-source\">📁 Data Source</div>\n",
    "        <div class=\"legend-item xml-nodes\">🏷️ XML Nodes</div>\n",
    "        <div class=\"legend-item traversal\">🔄 Traversal Logic</div>\n",
    "        <div class=\"legend-item output\">📋 Output</div>\n",
    "    </div>\n",
    "\n",
    "    <div class=\"flowchart-container\">\n",
    "        <svg class=\"flowchart-svg\" viewBox=\"0 0 950 550\" role=\"img\" aria-label=\"Enhanced flowchart of XML parsing and bilingual pair extraction\">\n",
    "            <defs>\n",
    "                <marker id=\"arrow\" viewBox=\"0 0 12 12\" refX=\"10\" refY=\"6\" markerWidth=\"10\" markerHeight=\"10\" orient=\"auto-start-reverse\">\n",
    "                    <path d=\"M 2 2 L 10 6 L 2 10 z\" fill=\"#4a5568\" stroke=\"#4a5568\" stroke-width=\"1\"/>\n",
    "                </marker>\n",
    "                \n",
    "                <linearGradient id=\"dataGradient\" x1=\"0%\" y1=\"0%\" x2=\"100%\" y2=\"100%\">\n",
    "                    <stop offset=\"0%\" style=\"stop-color:#e3f2fd;stop-opacity:1\" />\n",
    "                    <stop offset=\"100%\" style=\"stop-color:#bbdefb;stop-opacity:1\" />\n",
    "                </linearGradient>\n",
    "                \n",
    "                <linearGradient id=\"xmlGradient\" x1=\"0%\" y1=\"0%\" x2=\"100%\" y2=\"100%\">\n",
    "                    <stop offset=\"0%\" style=\"stop-color:#f3e5f5;stop-opacity:1\" />\n",
    "                    <stop offset=\"100%\" style=\"stop-color:#e1bee7;stop-opacity:1\" />\n",
    "                </linearGradient>\n",
    "                \n",
    "                <linearGradient id=\"traversalGradient\" x1=\"0%\" y1=\"0%\" x2=\"100%\" y2=\"100%\">\n",
    "                    <stop offset=\"0%\" style=\"stop-color:#e8f5e8;stop-opacity:1\" />\n",
    "                    <stop offset=\"100%\" style=\"stop-color:#c8e6c9;stop-opacity:1\" />\n",
    "                </linearGradient>\n",
    "                \n",
    "                <linearGradient id=\"outputGradient\" x1=\"0%\" y1=\"0%\" x2=\"100%\" y2=\"100%\">\n",
    "                    <stop offset=\"0%\" style=\"stop-color:#fff8e1;stop-opacity:1\" />\n",
    "                    <stop offset=\"100%\" style=\"stop-color:#ffecb3;stop-opacity:1\" />\n",
    "                </linearGradient>\n",
    "                \n",
    "                <filter id=\"shadow\" x=\"-20%\" y=\"-20%\" width=\"140%\" height=\"140%\">\n",
    "                    <feDropShadow dx=\"2\" dy=\"4\" stdDeviation=\"3\" flood-color=\"rgba(0,0,0,0.2)\"/>\n",
    "                </filter>\n",
    "            </defs>\n",
    "\n",
    "            <!-- Enhanced Boxes with gradients and shadows -->\n",
    "            <!-- Data source -->\n",
    "            <rect x=\"30\" y=\"30\" rx=\"12\" ry=\"12\" width=\"260\" height=\"80\" fill=\"url(#dataGradient)\" stroke=\"#90caf9\" stroke-width=\"2\" filter=\"url(#shadow)\"/>\n",
    "            <text x=\"160\" y=\"58\" text-anchor=\"middle\" font-size=\"16\" font-weight=\"600\" fill=\"#1565c0\">📁 Filesystem</text>\n",
    "            <text x=\"160\" y=\"78\" text-anchor=\"middle\" font-size=\"13\" fill=\"#1976d2\">base.glob(\"BDS*.xml\") → BDS*.xml</text>\n",
    "\n",
    "            <!-- Parse -->\n",
    "            <rect x=\"340\" y=\"30\" rx=\"12\" ry=\"12\" width=\"260\" height=\"80\" fill=\"url(#traversalGradient)\" stroke=\"#81c784\" stroke-width=\"2\" filter=\"url(#shadow)\"/>\n",
    "            <text x=\"470\" y=\"58\" text-anchor=\"middle\" font-size=\"16\" font-weight=\"600\" fill=\"#2e7d32\">🔍 Parse XML</text>\n",
    "            <text x=\"470\" y=\"78\" text-anchor=\"middle\" font-size=\"13\" fill=\"#388e3c\">ET.parse(xf).getroot()</text>\n",
    "\n",
    "            <!-- Root art -->\n",
    "            <rect x=\"650\" y=\"20\" rx=\"12\" ry=\"12\" width=\"260\" height=\"100\" fill=\"url(#xmlGradient)\" stroke=\"#ba68c8\" stroke-width=\"2\" filter=\"url(#shadow)\"/>\n",
    "            <text x=\"780\" y=\"50\" text-anchor=\"middle\" font-size=\"16\" font-weight=\"600\" fill=\"#7b1fa2\">🏷️ &lt;art&gt; (root)</text>\n",
    "            <text x=\"780\" y=\"70\" text-anchor=\"middle\" font-size=\"13\" fill=\"#8e24aa\">Attributes:</text>\n",
    "            <text x=\"780\" y=\"88\" text-anchor=\"middle\" font-size=\"13\" fill=\"#8e24aa\">orl=\"ja\", trl=\"en\"</text>\n",
    "\n",
    "            <!-- First level children -->\n",
    "            <rect x=\"80\" y=\"160\" rx=\"12\" ry=\"12\" width=\"320\" height=\"130\" fill=\"url(#xmlGradient)\" stroke=\"#ba68c8\" stroke-width=\"2\" filter=\"url(#shadow)\"/>\n",
    "            <text x=\"240\" y=\"185\" text-anchor=\"middle\" font-size=\"16\" font-weight=\"600\" fill=\"#7b1fa2\">📊 Level-1 Children</text>\n",
    "            <text x=\"240\" y=\"208\" text-anchor=\"middle\" font-size=\"13\" fill=\"#8e24aa\">for c in root → Counter([c.tag])</text>\n",
    "            <text x=\"240\" y=\"228\" text-anchor=\"middle\" font-size=\"13\" fill=\"#8e24aa\">strip_ns(tag) removes namespaces</text>\n",
    "            <text x=\"240\" y=\"248\" text-anchor=\"middle\" font-size=\"13\" fill=\"#8e24aa\">Prepares for sibling analysis</text>\n",
    "\n",
    "            <!-- Traversal logic -->\n",
    "            <rect x=\"460\" y=\"160\" rx=\"12\" ry=\"12\" width=\"380\" height=\"150\" fill=\"url(#traversalGradient)\" stroke=\"#81c784\" stroke-width=\"2\" filter=\"url(#shadow)\"/>\n",
    "            <text x=\"650\" y=\"185\" text-anchor=\"middle\" font-size=\"16\" font-weight=\"600\" fill=\"#2e7d32\">🔄 Sibling Lookup Logic</text>\n",
    "            <text x=\"650\" y=\"208\" text-anchor=\"middle\" font-size=\"12\" fill=\"#388e3c\">TAG_PAIR = None; TAG_ORIGINAL=\"j\"; TAG_TRANSL=\"e\"</text>\n",
    "            <text x=\"650\" y=\"228\" text-anchor=\"middle\" font-size=\"12\" fill=\"#388e3c\">For each node with children:</text>\n",
    "            <text x=\"650\" y=\"248\" text-anchor=\"middle\" font-size=\"12\" fill=\"#388e3c\">tagmap = { strip_ns(child.tag).lower(): child }</text>\n",
    "            <text x=\"650\" y=\"268\" text-anchor=\"middle\" font-size=\"12\" fill=\"#388e3c\">If \"j\" in tagmap and \"e\" in tagmap → extract texts</text>\n",
    "\n",
    "            <!-- Node with j/e -->\n",
    "            <rect x=\"120\" y=\"340\" rx=\"12\" ry=\"12\" width=\"330\" height=\"170\" fill=\"url(#xmlGradient)\" stroke=\"#ba68c8\" stroke-width=\"2\" filter=\"url(#shadow)\"/>\n",
    "            <text x=\"285\" y=\"365\" text-anchor=\"middle\" font-size=\"16\" font-weight=\"600\" fill=\"#7b1fa2\">🎯 Target Node Structure</text>\n",
    "\n",
    "            <rect x=\"150\" y=\"385\" rx=\"8\" ry=\"8\" width=\"130\" height=\"45\" fill=\"rgba(255,255,255,0.8)\" stroke=\"#ba68c8\" stroke-width=\"1.5\"/>\n",
    "            <text x=\"215\" y=\"410\" text-anchor=\"middle\" font-size=\"14\" font-weight=\"500\" fill=\"#7b1fa2\">&lt;j&gt; 日本語</text>\n",
    "\n",
    "            <rect x=\"290\" y=\"385\" rx=\"8\" ry=\"8\" width=\"130\" height=\"45\" fill=\"rgba(255,255,255,0.8)\" stroke=\"#ba68c8\" stroke-width=\"1.5\"/>\n",
    "            <text x=\"355\" y=\"410\" text-anchor=\"middle\" font-size=\"14\" font-weight=\"500\" fill=\"#7b1fa2\">&lt;e&gt; English</text>\n",
    "\n",
    "            <text x=\"285\" y=\"455\" text-anchor=\"middle\" font-size=\"12\" fill=\"#8e24aa\">text_or_none(el) trims and guards None</text>\n",
    "            <text x=\"285\" y=\"475\" text-anchor=\"middle\" font-size=\"12\" fill=\"#8e24aa\">Ensures clean text extraction</text>\n",
    "\n",
    "            <!-- Output pairs -->\n",
    "            <rect x=\"530\" y=\"350\" rx=\"12\" ry=\"12\" width=\"330\" height=\"140\" fill=\"url(#outputGradient)\" stroke=\"#ffb74d\" stroke-width=\"2\" filter=\"url(#shadow)\"/>\n",
    "            <text x=\"695\" y=\"375\" text-anchor=\"middle\" font-size=\"16\" font-weight=\"600\" fill=\"#f57c00\">📋 Output Pairs</text>\n",
    "            <text x=\"695\" y=\"398\" text-anchor=\"middle\" font-size=\"14\" fill=\"#ff9800\">List[Tuple[str, str]]</text>\n",
    "            <text x=\"695\" y=\"420\" text-anchor=\"middle\" font-size=\"13\" fill=\"#ff9800\">Append (ja, en) if both non-empty</text>\n",
    "            <text x=\"695\" y=\"440\" text-anchor=\"middle\" font-size=\"13\" fill=\"#ff9800\">pairs.append((ja, en))</text>\n",
    "            <text x=\"695\" y=\"460\" text-anchor=\"middle\" font-size=\"13\" fill=\"#ff9800\">Quality-filtered bilingual data</text>\n",
    "\n",
    "            <!-- Enhanced Arrows with better styling -->\n",
    "            <line x1=\"290\" y1=\"70\" x2=\"340\" y2=\"70\" stroke=\"#4a5568\" stroke-width=\"3\" marker-end=\"url(#arrow)\"/>\n",
    "            <line x1=\"600\" y1=\"70\" x2=\"650\" y2=\"70\" stroke=\"#4a5568\" stroke-width=\"3\" marker-end=\"url(#arrow)\"/>\n",
    "            <line x1=\"750\" y1=\"120\" x2=\"400\" y2=\"160\" stroke=\"#4a5568\" stroke-width=\"3\" marker-end=\"url(#arrow)\"/>\n",
    "            <line x1=\"400\" y1=\"225\" x2=\"460\" y2=\"235\" stroke=\"#4a5568\" stroke-width=\"3\" marker-end=\"url(#arrow)\"/>\n",
    "            <line x1=\"580\" y1=\"310\" x2=\"350\" y2=\"340\" stroke=\"#4a5568\" stroke-width=\"3\" marker-end=\"url(#arrow)\"/>\n",
    "            <line x1=\"450\" y1=\"420\" x2=\"530\" y2=\"420\" stroke=\"#4a5568\" stroke-width=\"3\" marker-end=\"url(#arrow)\"/>\n",
    "        </svg>\n",
    "    </div>\n",
    "\n",
    "    <div class=\"notes-section\">\n",
    "        <h3 class=\"notes-title\">💡 Implementation Details</h3>\n",
    "        <ul class=\"notes-list\">\n",
    "            <li><code>root.tag.endswith(\"art\")</code> and attribute validation ensure input conformity to <code>&lt;art orl=\"ja\" trl=\"en\"&gt;</code> schema.</li>\n",
    "            <li>When <code>TAG_PAIR is None</code>, the algorithm bypasses wrapper tags and directly scans nodes containing both <code>&lt;j&gt;</code> and <code>&lt;e&gt;</code> children.</li>\n",
    "            <li><code>strip_ns</code> function normalizes XML namespaces before comparison; all tag matching is case-insensitive.</li>\n",
    "            <li>Text extraction uses <code>text_or_none</code> with trimming and null guards—only non-empty content enters the final pairs collection.</li>\n",
    "            <li>The traversal algorithm scales efficiently across large XML documents with nested bilingual content structures.</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "</div>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79917e91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77f6dc56",
   "metadata": {},
   "source": [
    "### 4) inspect the newly created dataframe.  \n",
    "\n",
    "Does it make sense? were the tag correctly extracted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc14da3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ja</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>雪舟</td>\n",
       "      <td>Sesshu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>雪舟（せっしゅう、1420年（応永27年） - 1506年（永正3年））は号で、15世紀後半...</td>\n",
       "      <td>Known as Sesshu (1420 - 1506), he was an ink p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>日本の水墨画を一変させた。</td>\n",
       "      <td>He revolutionized the Japanese ink painting.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>諱は「等楊（とうよう）」、もしくは「拙宗（せっしゅう）」と号した。</td>\n",
       "      <td>He was given the posthumous name \"Toyo\" or \"Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>備中国に生まれ、京都・相国寺に入ってから周防国に移る。</td>\n",
       "      <td>Born in Bicchu Province, he moved to Suo Provi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  ja  \\\n",
       "0                                                 雪舟   \n",
       "1  雪舟（せっしゅう、1420年（応永27年） - 1506年（永正3年））は号で、15世紀後半...   \n",
       "2                                      日本の水墨画を一変させた。   \n",
       "3                  諱は「等楊（とうよう）」、もしくは「拙宗（せっしゅう）」と号した。   \n",
       "4                        備中国に生まれ、京都・相国寺に入ってから周防国に移る。   \n",
       "\n",
       "                                                  en  \n",
       "0                                             Sesshu  \n",
       "1  Known as Sesshu (1420 - 1506), he was an ink p...  \n",
       "2       He revolutionized the Japanese ink painting.  \n",
       "3  He was given the posthumous name \"Toyo\" or \"Se...  \n",
       "4  Born in Bicchu Province, he moved to Suo Provi...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a1c4bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pairs: 28384\n"
     ]
    }
   ],
   "source": [
    "print(\"Total pairs:\", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6b79d0",
   "metadata": {},
   "source": [
    "### 5) Prepare the data for machine translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5018480a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['ja']   # original \n",
    "y = df['en']   # translated\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, \n",
    "    test_size=0.1,  # for the validation set\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da77c98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Overview----\n",
      "\n",
      "Training set size: 20436 entries\n",
      "Testing set size: 5677 entries\n",
      "Validation set size: 2271 entries\n"
     ]
    }
   ],
   "source": [
    "# checks\n",
    "print(f\"----Overview----\")\n",
    "print(\"\")\n",
    "print(f\"Training set size: {len(X_train)} entries\")\n",
    "print(f\"Testing set size: {len(X_test)} entries\")\n",
    "print(f\"Validation set size: {len(X_val)} entries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66159d9",
   "metadata": {},
   "source": [
    "## Tokenization & Model \n",
    "\n",
    "The model selected is the multilingual Bart from Huggingface (https://huggingface.co/docs/transformers/en/model_doc/bart).   \n",
    "It will be set-up to be fine tuned on the dataset containing many historical and artistic information. Due to the resources required the model will not be trained, but his pre-trained version will be used instead.  \n",
    "\n",
    "Scoring will be performed from BLEU score, which evaluate the sequence of words between the generated sentence and the original, and also by BERTScore which evaluate instead the semantical similarity between the generated text and the reference one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9719e703",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
    "import torch\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "from sacrebleu import corpus_bleu, sentence_bleu\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import copy\n",
    "\n",
    "from bert_score import score\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu, SmoothingFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "010f1605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model and tokenizer initialization\n",
    "model_name=\"facebook/mbart-large-50-many-to-many-mmt\"\n",
    "tokenizer=MBart50TokenizerFast.from_pretrained(model_name)\n",
    "model=MBartForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9493413a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".mbart-container {\n",
       "    max-width: 700px;\n",
       "    margin: 20px auto;\n",
       "    padding: 25px;\n",
       "    background: #ffffff;\n",
       "    border: 2px solid #e1e5e9;\n",
       "    border-radius: 12px;\n",
       "    box-shadow: 0 4px 12px rgba(0,0,0,0.08);\n",
       "    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
       "    color: #2c3e50;\n",
       "}\n",
       "\n",
       ".header {\n",
       "    text-align: center;\n",
       "    margin-bottom: 25px;\n",
       "    padding-bottom: 15px;\n",
       "    border-bottom: 1px solid #e1e5e9;\n",
       "}\n",
       "\n",
       ".title {\n",
       "    font-size: 2.2em;\n",
       "    font-weight: 600;\n",
       "    margin: 0;\n",
       "    color: #34495e;\n",
       "    letter-spacing: -0.5px;\n",
       "}\n",
       "\n",
       ".subtitle {\n",
       "    font-size: 1.1em;\n",
       "    margin: 8px 0 0 0;\n",
       "    color: #7f8c8d;\n",
       "    font-weight: 400;\n",
       "}\n",
       "\n",
       ".architecture {\n",
       "    display: flex;\n",
       "    justify-content: center;\n",
       "    align-items: center;\n",
       "    margin: 30px 0;\n",
       "    gap: 20px;\n",
       "}\n",
       "\n",
       ".transformer-block {\n",
       "    background: #f8f9fa;\n",
       "    border: 1px solid #dee2e6;\n",
       "    border-radius: 8px;\n",
       "    padding: 18px 24px;\n",
       "    text-align: center;\n",
       "    min-width: 140px;\n",
       "    transition: all 0.2s ease;\n",
       "}\n",
       "\n",
       ".transformer-block:hover {\n",
       "    background: #e9ecef;\n",
       "    border-color: #adb5bd;\n",
       "}\n",
       "\n",
       ".transformer-block h3 {\n",
       "    margin: 0 0 8px 0;\n",
       "    font-size: 1.1em;\n",
       "    color: #495057;\n",
       "    font-weight: 500;\n",
       "}\n",
       "\n",
       ".transformer-block p {\n",
       "    margin: 0;\n",
       "    font-size: 0.9em;\n",
       "    color: #6c757d;\n",
       "    line-height: 1.3;\n",
       "}\n",
       "\n",
       ".arrow {\n",
       "    font-size: 1.5em;\n",
       "    color: #6c757d;\n",
       "}\n",
       "\n",
       ".language-pair {\n",
       "    display: flex;\n",
       "    justify-content: center;\n",
       "    align-items: center;\n",
       "    gap: 25px;\n",
       "    margin: 25px 0;\n",
       "    padding: 20px;\n",
       "    background: #f8f9fa;\n",
       "    border-radius: 8px;\n",
       "    border-left: 4px solid #3498db;\n",
       "}\n",
       "\n",
       ".language {\n",
       "    text-align: center;\n",
       "    flex: 1;\n",
       "}\n",
       "\n",
       ".language-flag {\n",
       "    font-size: 2.5em;\n",
       "    margin-bottom: 8px;\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".language-name {\n",
       "    font-size: 1.1em;\n",
       "    font-weight: 500;\n",
       "    color: #2c3e50;\n",
       "    margin: 0;\n",
       "}\n",
       "\n",
       ".translation-arrow {\n",
       "    font-size: 1.8em;\n",
       "    color: #3498db;\n",
       "}\n",
       "\n",
       ".features {\n",
       "    display: grid;\n",
       "    grid-template-columns: 1fr 1fr;\n",
       "    gap: 15px;\n",
       "    margin: 25px 0;\n",
       "}\n",
       "\n",
       ".feature {\n",
       "    background: #ffffff;\n",
       "    border: 1px solid #dee2e6;\n",
       "    border-radius: 6px;\n",
       "    padding: 16px;\n",
       "}\n",
       "\n",
       ".feature h4 {\n",
       "    margin: 0 0 8px 0;\n",
       "    font-size: 1em;\n",
       "    color: #495057;\n",
       "    font-weight: 500;\n",
       "}\n",
       "\n",
       ".feature p {\n",
       "    margin: 0;\n",
       "    font-size: 0.9em;\n",
       "    color: #6c757d;\n",
       "    line-height: 1.4;\n",
       "}\n",
       "\n",
       ".stats {\n",
       "    display: flex;\n",
       "    justify-content: center;\n",
       "    gap: 40px;\n",
       "    margin-top: 25px;\n",
       "    padding-top: 20px;\n",
       "    border-top: 1px solid #e1e5e9;\n",
       "}\n",
       "\n",
       ".stat {\n",
       "    text-align: center;\n",
       "}\n",
       "\n",
       ".stat-number {\n",
       "    font-size: 1.6em;\n",
       "    font-weight: 600;\n",
       "    color: #2c3e50;\n",
       "    display: block;\n",
       "    margin-bottom: 4px;\n",
       "}\n",
       "\n",
       ".stat-label {\n",
       "    font-size: 0.9em;\n",
       "    color: #7f8c8d;\n",
       "}\n",
       "\n",
       "@media (max-width: 600px) {\n",
       "    .mbart-container {\n",
       "        margin: 10px;\n",
       "        padding: 20px;\n",
       "    }\n",
       "    \n",
       "    .title {\n",
       "        font-size: 1.8em;\n",
       "    }\n",
       "    \n",
       "    .architecture {\n",
       "        flex-direction: column;\n",
       "        gap: 15px;\n",
       "    }\n",
       "    \n",
       "    .arrow {\n",
       "        transform: rotate(90deg);\n",
       "    }\n",
       "\n",
       "    .language-pair {\n",
       "        flex-direction: column;\n",
       "        gap: 15px;\n",
       "    }\n",
       "\n",
       "    .translation-arrow {\n",
       "        transform: rotate(90deg);\n",
       "    }\n",
       "\n",
       "    .features {\n",
       "        grid-template-columns: 1fr;\n",
       "    }\n",
       "\n",
       "    .stats {\n",
       "        gap: 20px;\n",
       "    }\n",
       "}\n",
       "</style>\n",
       "\n",
       "<div class=\"mbart-container\">\n",
       "    <div class=\"header\">\n",
       "        <h1 class=\"title\">mBART</h1>\n",
       "        <p class=\"subtitle\">Multilingual Bidirectional and Auto-Regressive Transformers</p>\n",
       "    </div>\n",
       "\n",
       "    <div class=\"architecture\">\n",
       "        <div class=\"transformer-block\">\n",
       "            <h3>Encoder</h3>\n",
       "            <p>Bidirectional<br>Context Understanding</p>\n",
       "        </div>\n",
       "        <div class=\"arrow\">→</div>\n",
       "        <div class=\"transformer-block\">\n",
       "            <h3>Decoder</h3>\n",
       "            <p>Auto-Regressive<br>Text Generation</p>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <div class=\"language-pair\">\n",
       "        <div class=\"language\">\n",
       "            <span class=\"language-flag\">🇺🇸</span>\n",
       "            <p class=\"language-name\">English</p>\n",
       "        </div>\n",
       "        <div class=\"translation-arrow\">⇄</div>\n",
       "        <div class=\"language\">\n",
       "            <span class=\"language-flag\">🇯🇵</span>\n",
       "            <p class=\"language-name\">Japanese</p>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <div class=\"features\">\n",
       "        <div class=\"feature\">\n",
       "            <h4>Pre-trained Model</h4>\n",
       "            <p>Trained on multilingual corpora with denoising objectives</p>\n",
       "        </div>\n",
       "        <div class=\"feature\">\n",
       "            <h4>Fine-tuned Translation</h4>\n",
       "            <p>Optimized for English-Japanese bidirectional translation</p>\n",
       "        </div>\n",
       "        <div class=\"feature\">\n",
       "            <h4>Cross-lingual Transfer</h4>\n",
       "            <p>Leverages shared representations across languages</p>\n",
       "        </div>\n",
       "        <div class=\"feature\">\n",
       "            <h4>State-of-the-art Performance</h4>\n",
       "            <p>Competitive results on translation benchmarks</p>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <div class=\"stats\">\n",
       "        <div class=\"stat\">\n",
       "            <span class=\"stat-number\">~610M</span>\n",
       "            <span class=\"stat-label\">Parameters</span>\n",
       "        </div>\n",
       "        <div class=\"stat\">\n",
       "            <span class=\"stat-number\">24</span>\n",
       "            <span class=\"stat-label\">Layers</span>\n",
       "        </div>\n",
       "        <div class=\"stat\">\n",
       "            <span class=\"stat-number\">50</span>\n",
       "            <span class=\"stat-label\">Languages</span>\n",
       "        </div>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<style>\n",
    ".mbart-container {\n",
    "    max-width: 700px;\n",
    "    margin: 20px auto;\n",
    "    padding: 25px;\n",
    "    background: #ffffff;\n",
    "    border: 2px solid #e1e5e9;\n",
    "    border-radius: 12px;\n",
    "    box-shadow: 0 4px 12px rgba(0,0,0,0.08);\n",
    "    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
    "    color: #2c3e50;\n",
    "}\n",
    "\n",
    ".header {\n",
    "    text-align: center;\n",
    "    margin-bottom: 25px;\n",
    "    padding-bottom: 15px;\n",
    "    border-bottom: 1px solid #e1e5e9;\n",
    "}\n",
    "\n",
    ".title {\n",
    "    font-size: 2.2em;\n",
    "    font-weight: 600;\n",
    "    margin: 0;\n",
    "    color: #34495e;\n",
    "    letter-spacing: -0.5px;\n",
    "}\n",
    "\n",
    ".subtitle {\n",
    "    font-size: 1.1em;\n",
    "    margin: 8px 0 0 0;\n",
    "    color: #7f8c8d;\n",
    "    font-weight: 400;\n",
    "}\n",
    "\n",
    ".architecture {\n",
    "    display: flex;\n",
    "    justify-content: center;\n",
    "    align-items: center;\n",
    "    margin: 30px 0;\n",
    "    gap: 20px;\n",
    "}\n",
    "\n",
    ".transformer-block {\n",
    "    background: #f8f9fa;\n",
    "    border: 1px solid #dee2e6;\n",
    "    border-radius: 8px;\n",
    "    padding: 18px 24px;\n",
    "    text-align: center;\n",
    "    min-width: 140px;\n",
    "    transition: all 0.2s ease;\n",
    "}\n",
    "\n",
    ".transformer-block:hover {\n",
    "    background: #e9ecef;\n",
    "    border-color: #adb5bd;\n",
    "}\n",
    "\n",
    ".transformer-block h3 {\n",
    "    margin: 0 0 8px 0;\n",
    "    font-size: 1.1em;\n",
    "    color: #495057;\n",
    "    font-weight: 500;\n",
    "}\n",
    "\n",
    ".transformer-block p {\n",
    "    margin: 0;\n",
    "    font-size: 0.9em;\n",
    "    color: #6c757d;\n",
    "    line-height: 1.3;\n",
    "}\n",
    "\n",
    ".arrow {\n",
    "    font-size: 1.5em;\n",
    "    color: #6c757d;\n",
    "}\n",
    "\n",
    ".language-pair {\n",
    "    display: flex;\n",
    "    justify-content: center;\n",
    "    align-items: center;\n",
    "    gap: 25px;\n",
    "    margin: 25px 0;\n",
    "    padding: 20px;\n",
    "    background: #f8f9fa;\n",
    "    border-radius: 8px;\n",
    "    border-left: 4px solid #3498db;\n",
    "}\n",
    "\n",
    ".language {\n",
    "    text-align: center;\n",
    "    flex: 1;\n",
    "}\n",
    "\n",
    ".language-flag {\n",
    "    font-size: 2.5em;\n",
    "    margin-bottom: 8px;\n",
    "    display: block;\n",
    "}\n",
    "\n",
    ".language-name {\n",
    "    font-size: 1.1em;\n",
    "    font-weight: 500;\n",
    "    color: #2c3e50;\n",
    "    margin: 0;\n",
    "}\n",
    "\n",
    ".translation-arrow {\n",
    "    font-size: 1.8em;\n",
    "    color: #3498db;\n",
    "}\n",
    "\n",
    ".features {\n",
    "    display: grid;\n",
    "    grid-template-columns: 1fr 1fr;\n",
    "    gap: 15px;\n",
    "    margin: 25px 0;\n",
    "}\n",
    "\n",
    ".feature {\n",
    "    background: #ffffff;\n",
    "    border: 1px solid #dee2e6;\n",
    "    border-radius: 6px;\n",
    "    padding: 16px;\n",
    "}\n",
    "\n",
    ".feature h4 {\n",
    "    margin: 0 0 8px 0;\n",
    "    font-size: 1em;\n",
    "    color: #495057;\n",
    "    font-weight: 500;\n",
    "}\n",
    "\n",
    ".feature p {\n",
    "    margin: 0;\n",
    "    font-size: 0.9em;\n",
    "    color: #6c757d;\n",
    "    line-height: 1.4;\n",
    "}\n",
    "\n",
    ".stats {\n",
    "    display: flex;\n",
    "    justify-content: center;\n",
    "    gap: 40px;\n",
    "    margin-top: 25px;\n",
    "    padding-top: 20px;\n",
    "    border-top: 1px solid #e1e5e9;\n",
    "}\n",
    "\n",
    ".stat {\n",
    "    text-align: center;\n",
    "}\n",
    "\n",
    ".stat-number {\n",
    "    font-size: 1.6em;\n",
    "    font-weight: 600;\n",
    "    color: #2c3e50;\n",
    "    display: block;\n",
    "    margin-bottom: 4px;\n",
    "}\n",
    "\n",
    ".stat-label {\n",
    "    font-size: 0.9em;\n",
    "    color: #7f8c8d;\n",
    "}\n",
    "\n",
    "@media (max-width: 600px) {\n",
    "    .mbart-container {\n",
    "        margin: 10px;\n",
    "        padding: 20px;\n",
    "    }\n",
    "    \n",
    "    .title {\n",
    "        font-size: 1.8em;\n",
    "    }\n",
    "    \n",
    "    .architecture {\n",
    "        flex-direction: column;\n",
    "        gap: 15px;\n",
    "    }\n",
    "    \n",
    "    .arrow {\n",
    "        transform: rotate(90deg);\n",
    "    }\n",
    "\n",
    "    .language-pair {\n",
    "        flex-direction: column;\n",
    "        gap: 15px;\n",
    "    }\n",
    "\n",
    "    .translation-arrow {\n",
    "        transform: rotate(90deg);\n",
    "    }\n",
    "\n",
    "    .features {\n",
    "        grid-template-columns: 1fr;\n",
    "    }\n",
    "\n",
    "    .stats {\n",
    "        gap: 20px;\n",
    "    }\n",
    "}\n",
    "</style>\n",
    "\n",
    "<div class=\"mbart-container\">\n",
    "    <div class=\"header\">\n",
    "        <h1 class=\"title\">mBART</h1>\n",
    "        <p class=\"subtitle\">Multilingual Bidirectional and Auto-Regressive Transformers</p>\n",
    "    </div>\n",
    "\n",
    "    <div class=\"architecture\">\n",
    "        <div class=\"transformer-block\">\n",
    "            <h3>Encoder</h3>\n",
    "            <p>Bidirectional<br>Context Understanding</p>\n",
    "        </div>\n",
    "        <div class=\"arrow\">→</div>\n",
    "        <div class=\"transformer-block\">\n",
    "            <h3>Decoder</h3>\n",
    "            <p>Auto-Regressive<br>Text Generation</p>\n",
    "        </div>\n",
    "    </div>\n",
    "\n",
    "    <div class=\"language-pair\">\n",
    "        <div class=\"language\">\n",
    "            <span class=\"language-flag\">🇺🇸</span>\n",
    "            <p class=\"language-name\">English</p>\n",
    "        </div>\n",
    "        <div class=\"translation-arrow\">⇄</div>\n",
    "        <div class=\"language\">\n",
    "            <span class=\"language-flag\">🇯🇵</span>\n",
    "            <p class=\"language-name\">Japanese</p>\n",
    "        </div>\n",
    "    </div>\n",
    "\n",
    "    <div class=\"features\">\n",
    "        <div class=\"feature\">\n",
    "            <h4>Pre-trained Model</h4>\n",
    "            <p>Trained on multilingual corpora with denoising objectives</p>\n",
    "        </div>\n",
    "        <div class=\"feature\">\n",
    "            <h4>Fine-tuned Translation</h4>\n",
    "            <p>Optimized for English-Japanese bidirectional translation</p>\n",
    "        </div>\n",
    "        <div class=\"feature\">\n",
    "            <h4>Cross-lingual Transfer</h4>\n",
    "            <p>Leverages shared representations across languages</p>\n",
    "        </div>\n",
    "        <div class=\"feature\">\n",
    "            <h4>State-of-the-art Performance</h4>\n",
    "            <p>Competitive results on translation benchmarks</p>\n",
    "        </div>\n",
    "    </div>\n",
    "\n",
    "    <div class=\"stats\">\n",
    "        <div class=\"stat\">\n",
    "            <span class=\"stat-number\">~610M</span>\n",
    "            <span class=\"stat-label\">Parameters</span>\n",
    "        </div>\n",
    "        <div class=\"stat\">\n",
    "            <span class=\"stat-number\">24</span>\n",
    "            <span class=\"stat-label\">Layers</span>\n",
    "        </div>\n",
    "        <div class=\"stat\">\n",
    "            <span class=\"stat-number\">50</span>\n",
    "            <span class=\"stat-label\">Languages</span>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56f255d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.src_lang= \"ja_XX\"   # source language (original) = japanese\n",
    "tokenizer.tgt_lang= \"en_XX\"    # translated language  = english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11a9a601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    inputs= tokenizer(\n",
    "        examples['ja'], \n",
    "        max_length=128, \n",
    "        truncation=True, \n",
    "        padding=True\n",
    "    )\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels=tokenizer(\n",
    "            examples['en'], \n",
    "            max_length=128, \n",
    "            truncation=True, \n",
    "            padding=True\n",
    "        )\n",
    "    inputs[\"labels\"]=labels[\"input_ids\"]\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b67c583",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(pd.DataFrame({\n",
    "    'ja': X_train, \n",
    "    'en': y_train\n",
    "}))\n",
    "\n",
    "val_dataset = Dataset.from_pandas(pd.DataFrame({\n",
    "    'ja': X_val, \n",
    "    'en': y_val\n",
    "}))\n",
    "\n",
    "test_df=pd.DataFrame({'ja': X_test, 'en':y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1d478bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/20436 [00:00<?, ? examples/s]c:\\Users\\laran\\Home\\Documents\\code\\venv\\NLPvenv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3961: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map: 100%|██████████| 20436/20436 [00:01<00:00, 12696.05 examples/s]\n",
      "Map: 100%|██████████| 2271/2271 [00:00<00:00, 14778.19 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset=train_dataset.map(preprocess_function, batched=True)\n",
    "val_dataset=val_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0967131",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator=DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer, \n",
    "    model=model, \n",
    "    padding=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1bf2b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU count: 1\n",
      "Current GPU: NVIDIA GeForce RTX 4070 Laptop GPU\n",
      "GPU memory: 8.6 GB\n"
     ]
    }
   ],
   "source": [
    "# GPU setup\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"GPU count: {torch.cuda.device_count()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Current GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "91fefb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "print(f\"Model is on: {model.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d00300b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\laran\\Home\\Documents\\code\\venv\\NLPvenv\\Lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./mbart-cultural-ja-en',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=1000,\n",
    "    save_steps=2000,\n",
    "    load_best_model_at_end=True,\n",
    "    fp16=True,  # Enables mixed precision - faster training on modern GPUs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7afe2482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using batch size: 4\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    gpu_memory_gb = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    \n",
    "    if gpu_memory_gb >= 16:\n",
    "        batch_size = 8  # Can handle larger batches\n",
    "    elif gpu_memory_gb >= 8:\n",
    "        batch_size = 4  # Your current setting\n",
    "    else:\n",
    "        batch_size = 2  # Smaller GPU\n",
    "        \n",
    "    print(f\"Using batch size: {batch_size}\")\n",
    "    \n",
    "    # Update your training args\n",
    "    training_args.per_device_train_batch_size = batch_size\n",
    "    training_args.per_device_eval_batch_size = batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "000a006d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laran\\AppData\\Local\\Temp\\ipykernel_42104\\1253686246.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer=Trainer(\n"
     ]
    }
   ],
   "source": [
    "trainer=Trainer(\n",
    "    model=model, \n",
    "    args=training_args, \n",
    "    train_dataset=train_dataset, \n",
    "    eval_dataset=val_dataset, \n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4c2f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Starting training...\")\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff786f9",
   "metadata": {},
   "source": [
    "Time required is approx 15h training. We will use a pre-trained model without MLE fine tutning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "87ceeed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using sample 8 from test dataset\n",
      "Japanese: 当寺の実質的な開山は碧潭周皎であるが、碧潭は法兄である夢窓疎石を勧請開山としている。\n",
      "English reference: Although the actual kaisan (a temple founder as the first chief priest) of the temple was Hekitan Shuko, Hekitan treated Muso Soseki, his priest brother, as a kanjo kaizan.\n",
      "Model translation: Although the actual opening of the temple was Zhou Ying of Bitan Temple, Zhou Ying of Bitan Temple called for the opening of the temple by inviting Yumo Shuishi, a Buddhist elder brother.\n"
     ]
    }
   ],
   "source": [
    "sample_idx= 8\n",
    "test_ja=X_test.iloc[sample_idx]\n",
    "test_en_reference=y_test.iloc[sample_idx]\n",
    "beam_size=5\n",
    "\n",
    "inputs = tokenizer(test_ja, return_tensors=\"pt\").to(\"cuda\")\n",
    "outputs = model.generate(**inputs, forced_bos_token_id=tokenizer.lang_code_to_id[\"en_XX\"])\n",
    "result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(f\"Using sample {sample_idx} from test dataset\")\n",
    "print(f\"Japanese: {test_ja}\")\n",
    "print(f\"English reference: {test_en_reference}\")\n",
    "print(f\"Model translation: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e1b012c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model evaluation before optimization\n",
      "####################\n",
      " \n",
      "Evaluating on 100 samples...\n",
      "\n",
      "Example 1:\n",
      "JA:  1917年（大正6年）勧学が追贈されている。\n",
      "REF: In 1917, he was promoted to Kangaku ranking after his death.\n",
      "GEN: In 1917, he was promoted to Kangaku.\n",
      "BLEU: 45.69, BERTScore F1: 0.963\n",
      "\n",
      "Example 2:\n",
      "JA:  それゆえに直日・直堂も、修行者も、両者ともが警策を「与える」・「いただく」前後に合掌低頭し、お互いに感謝の意を表わす。\n",
      "REF: Therefore, both of Jikijitsu or jikido and meditators make the gassho (place the palms of the hands together in the position of prayer) and bow their head to show their gratitude each other, before and after the keisaku (kyosaku) is to \"give\" and \"receive\".\n",
      "GEN: Therefore, both Naoki and Naodo, as well as the practitioners, both \"give\" and \"receive\" the precaution, holding their hands and lowering their heads, expressing their gratitude to each other.\n",
      "BLEU: 1.75, BERTScore F1: 0.878\n",
      "\n",
      "Example 3:\n",
      "JA:  古市 胤栄（ふるいち いんえい、生年不詳 - 永正2年（1505年））は、戦国時代 (日本)の僧・武将。\n",
      "REF: Ine FURUICHI (year of birth unknown - 1505) is a priest and a Japanese military commander during the Sengoku period.\n",
      "GEN: Taneie Furuichi (year of birth unknown - 1505) was a Buddhist monk and warrior in the Sengoku period (Japan).\n",
      "BLEU: 28.14, BERTScore F1: 0.932\n",
      "\n",
      "Example 4:\n",
      "JA:  道忠自身は鑑真の弟子で、律宗の僧侶であったが、戒壇が設けられた下野薬師寺との関連か東国に住し、広く弟子を持つ僧侶であった。\n",
      "REF: Dochu himself was a disciple of Ganjin and a Buddhist priest in Ritsu sect, but he lived in Togoku maybe because he had a relationship with Shimotsuke Yakushi-ji Temple which had Kaidan (Buddhist ordination platform) and he had many disciples across a wide range.\n",
      "GEN: Michitada himself was a disciple of Kanshin and was a priest of the Ritsuryo sect, but he lived in the eastern country in connection with Shimono Yakushi-ji Temple, where the戒壇 was established, and had a large number of disciples.\n",
      "BLEU: 18.78, BERTScore F1: 0.903\n",
      "\n",
      "Example 5:\n",
      "JA:  つまり、律令体制下の仏教で国家の庇護を受けて仏教の研究を行い、宗教上の実践行為は鎮護国家という理念の下で呪術的な祈祷を行う程度であったといわれる。\n",
      "REF: In other words, they were the Buddhism under the Ritsuryo system; the priests of these sects were just scholars studying Buddhism under the protection of the nation, and as for actual religious activity, they just performed some magical prayers for the idea of Chingo-Kokka (guarding the nation by Buddhism).\n",
      "GEN: In other words, they studied Buddhism under the Ritsuryo system under the protection of the state, and religious practice was to the extent that they performed magical prayers under the philosophy of protecting the state.\n",
      "BLEU: 18.37, BERTScore F1: 0.913\n"
     ]
    }
   ],
   "source": [
    "print(\"model evaluation before optimization\")\n",
    "print(\"#\"*20)\n",
    "print(\" \")\n",
    "\n",
    "baseline_results = utils.evaluate_model(model, tokenizer, X_test, y_test, max_samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c88869f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre_optimization metrics\n",
      "####################\n",
      "Corpus BLEU: 14.98\n",
      "Corpus Bert: 0.90\n",
      "Average Sentence BLEU: 10.95 ± 13.94\n"
     ]
    }
   ],
   "source": [
    "print(\"pre_optimization metrics\")\n",
    "print(\"#\"*20)\n",
    "print(f\"Corpus BLEU: {baseline_results['corpus_bleu']:.2f}\")\n",
    "print(f\"Corpus Bert: {baseline_results['corpus_bert']:.2f}\")\n",
    "print(f\"Average Sentence BLEU: {baseline_results['avg_sentence_bleu']:.2f} ± {baseline_results['std_sentence_bleu']:.2f}\")\n",
    "\n",
    "baseline_corpus_bleu=baseline_results['corpus_bleu']\n",
    "baseline_corpus_bert=baseline_results['corpus_bert']\n",
    "baseline_avg_bleu=baseline_results['avg_sentence_bleu']   \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4317ac6d",
   "metadata": {},
   "source": [
    "##  Model optimization through RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefbd1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bleu_reward(generated_text, reference_text):\n",
    "    \"\"\"Compute sentence-level BLEU as reward\"\"\"\n",
    "    try:\n",
    "        bleu = sentence_bleu(generated_text, [reference_text]).score / 100.0\n",
    "        return max(bleu, 0.01)  # Avoid zero rewards\n",
    "    except:\n",
    "        return 0.01\n",
    "    \n",
    "def compute_bert_reward(generated_text, reference_text):\n",
    "    \"\"\"Compute semantic level Bert score as reward\"\"\"\n",
    "    P, R, F1 = score(\n",
    "        [generated_text], \n",
    "        [reference_text], \n",
    "        lang=\"en\",\n",
    "        verbose=False,\n",
    "    )\n",
    "    return F1.item()\n",
    "\n",
    "def rl_training_step(model, tokenizer, batch_ja, batch_en_ref, optimizer):\n",
    "    \"\"\"Single RL training step using reinforcement learning\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for ja_text, en_ref in zip(batch_ja, batch_en_ref):\n",
    "        # Tokenize input\n",
    "        #inputs = tokenizer(ja_text, return_tensors=\"pt\", max_length=128, truncation=True).to(\"cuda\")\n",
    "        inputs = tokenizer(ja_text, return_tensors=\"pt\", truncation=False).to(\"cuda\")\n",
    "        \n",
    "        # not greedy --> RL\n",
    "        with torch.no_grad():\n",
    "            generated_outputs = model.generate(\n",
    "                **inputs,\n",
    "                forced_bos_token_id=tokenizer.lang_code_to_id[\"en_XX\"],\n",
    "                # max_length=128,\n",
    "                do_sample=True,  # must sample for RL\n",
    "                temperature=1.0,\n",
    "                pad_token_id=tokenizer.pad_token_id,\n",
    "                return_dict_in_generate=True,\n",
    "                output_scores=True\n",
    "            )\n",
    "        \n",
    "        # reward setup\n",
    "        generated_ids = generated_outputs.sequences[0]\n",
    "        generated_text = tokenizer.decode(generated_ids, skip_special_tokens=True)\n",
    "        bleu_reward = compute_bleu_reward(generated_text, en_ref)\n",
    "        bert_reward=compute_bert_reward(generated_text, en_ref)\n",
    "\n",
    "        reward=0.5* bleu_reward + 0.5* bert_reward\n",
    "        reward=float(reward)\n",
    "        \n",
    "        # forward pass\n",
    "        decoder_input_ids = generated_ids[:-1].unsqueeze(0)  # remove last token\n",
    "        labels = generated_ids[1:].unsqueeze(0)  \n",
    "        \n",
    "        outputs = model(\n",
    "            input_ids=inputs.input_ids,\n",
    "            decoder_input_ids=decoder_input_ids,\n",
    "            labels=labels\n",
    "        )\n",
    "        \n",
    "        log_probs = F.log_softmax(outputs.logits, dim=-1)\n",
    "        selected_log_probs = log_probs.gather(2, labels.unsqueeze(-1)).squeeze(-1)\n",
    "        \n",
    "        # Policy grandient negative to maximize reward\n",
    "        loss = -selected_log_probs.mean() * reward\n",
    "        total_loss += loss \n",
    "\n",
    "        print(f\"JA: {ja_text[:50]}...\")\n",
    "        print(f\"Generated: {generated_text}\")\n",
    "        print(f\"Reference: {en_ref}\")\n",
    "        print(f\"BLEU Reward: {reward:.3f}\")\n",
    "        print(f\"Loss: {loss.item():.3f}\")\n",
    "        print(\"-\" * 60)\n",
    "    \n",
    "    # update to new state\n",
    "    avg_loss = total_loss / len(batch_ja)\n",
    "    avg_loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    return avg_loss.item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d5738b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copying th eoriginal model to have a comparison after optimization\n",
    "\n",
    "model_baseline = copy.deepcopy(model)\n",
    "model_baseline.eval()\n",
    "model_RL = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6131c163",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting RL training\n",
      "####################\n",
      "\n",
      "--- RL Step 1/100 ---\n",
      "JA: 行者には、次の意味がある。...\n",
      "Generated: The line has the following meaning.\n",
      "Reference: Gyoja or Anja has the following meanings.\n",
      "BLEU Reward: 0.451\n",
      "Loss: 0.226\n",
      "------------------------------------------------------------\n",
      "JA: また立川飛行機の庶務課より丑寅の方角を警戒するようにと示されたので、関係者に注意し消化設備に万全を期...\n",
      "Generated: It was also directed by the Michikawa aircraft's general affairs division to be vigilant.\n",
      "Reference: He gave a warning to General Affairs Division of Tachikawa Aircraft to be on guard in the direction of northeast and instructed those concerned to carefully set up fire-extinguishing equipment.\n",
      "BLEU Reward: 0.451\n",
      "Loss: 0.236\n",
      "------------------------------------------------------------\n",
      "Average Loss: 0.2313\n",
      "\n",
      "--- RL Step 2/100 ---\n",
      "JA: 南北朝時代 (日本)に東寺の僧、杲宝（ごうほう）・賢宝（げんぼう）らにより東寺不二門教学を大成させて...\n",
      "Generated: In the period of the Northern and Southern Ages, he preached the local priesthood.\n",
      "Reference: During the period of the Northern and Southern Courts (Japan) To-ji Temple's priests such as Goho and Kenpo completed Tojifujimonkyogaku (東寺不二門教学) and taught Honchikajisetsu (本地加持説) (Kogi) of Dainichinyorai.\n",
      "BLEU Reward: 0.420\n",
      "Loss: 0.277\n",
      "------------------------------------------------------------\n",
      "JA: 能円...\n",
      "Generated: Noh\n",
      "Reference: Noen\n",
      "BLEU Reward: 0.432\n",
      "Loss: 0.018\n",
      "------------------------------------------------------------\n",
      "Average Loss: 0.1474\n",
      "\n",
      "--- RL Step 3/100 ---\n",
      "JA: その結果、殺人・姦盗以外は仏教の戒律に基づいて処分することが認められた。...\n",
      "Generated: As a result, it was allowed to be disposed of.\n",
      "Reference: Consequently it became possible to apply the Buddhist precepts to the cases other than murder and theft.\n",
      "BLEU Reward: 0.439\n",
      "Loss: 0.195\n",
      "------------------------------------------------------------\n",
      "JA: 日代は重須を追い出され、後に西山本門寺を開き、初代住職となっている。...\n",
      "Generated: Nichito was expelled.\n",
      "Reference: Nichidai was thrown out from Omosu, later founded Nishiyama Honmon-ji Temple, and assumed the position of the first chief priest there.\n",
      "BLEU Reward: 0.424\n",
      "Loss: 0.015\n",
      "------------------------------------------------------------\n",
      "Average Loss: 0.1052\n",
      "\n",
      "--- RL Step 4/100 ---\n",
      "JA: 道正庵と号した。...\n",
      "Generated: It was called道正庵.\n",
      "Reference: The hut and also himself was called \"Dosho-an\".\n",
      "BLEU Reward: 0.432\n",
      "Loss: 0.013\n",
      "------------------------------------------------------------\n",
      "JA: 江戸時代には虚無僧の集団が形成された特殊な宗派であった。...\n",
      "Generated: It was a special sect.\n",
      "Reference: In the Edo period, Fuke sect was a special religious school that was formed by group of komuso.\n",
      "BLEU Reward: 0.444\n",
      "Loss: 0.017\n",
      "------------------------------------------------------------\n",
      "Average Loss: 0.0151\n",
      "\n",
      "--- RL Step 5/100 ---\n",
      "JA: 滋賀院（しがいん）は、滋賀県大津市坂本 (大津市)にある天台宗の寺院で比叡山延暦寺の本坊（総里坊）で...\n",
      "Generated: Shigain.\n",
      "Reference: Shiga-in Temple, a temple of the Tendai sect located in Sakamoto, Otsu City, Shiga Prefecture, s a honbo (a priest's main living quarters) (Sosatobo) of Enryaku-ji Temple on Mt. Hiei.\n",
      "BLEU Reward: 0.399\n",
      "Loss: 0.045\n",
      "------------------------------------------------------------\n",
      "JA: 信者は、既存の寺の教えを表法と呼び、隠し念仏の教えを内法（内信心）と呼んでいる。...\n",
      "Generated: The believers called the teachings of the existing temples.\n",
      "Reference: The believers call the existing teachings of a temple the outward law, and call the teachings of kakushi nenbutsu the inward law (or the inward belief).\n",
      "BLEU Reward: 0.449\n",
      "Loss: 0.027\n",
      "------------------------------------------------------------\n",
      "Average Loss: 0.0363\n",
      "\n",
      "--- RL Step 6/100 ---\n",
      "JA: 滋賀院（しがいん）は、滋賀県大津市坂本 (大津市)にある天台宗の寺院で比叡山延暦寺の本坊（総里坊）で...\n",
      "Generated: Shigain.\n",
      "Reference: Shiga-in Temple, a temple of the Tendai sect located in Sakamoto, Otsu City, Shiga Prefecture, s a honbo (a priest's main living quarters) (Sosatobo) of Enryaku-ji Temple on Mt. Hiei.\n",
      "BLEU Reward: 0.399\n",
      "Loss: 0.018\n",
      "------------------------------------------------------------\n",
      "JA: 高野山金剛峯寺に大伝法院を建立し座主に就任したのを皮切りに、金剛峯寺座主にも兼ねて就任し事実上同山の...\n",
      "Generated: At the beginning, he established the Daen-ji Temple at Mt. Koen.\n",
      "Reference: First he erected Daidenpo-in Temple in Koyasan Kongobuji Temple and became the head priest, and then he also assumed the head priest of Kongobuji Temple and in effect gained the initiative of the Mountain.\n",
      "BLEU Reward: 0.447\n",
      "Loss: 0.130\n",
      "------------------------------------------------------------\n",
      "Average Loss: 0.0738\n",
      "\n",
      "--- RL Step 7/100 ---\n",
      "JA: 平成3年、87歳で寂。...\n",
      "Generated: In 1997, I was lonely.\n",
      "Reference: In 1991, he passed away at the age of 87.\n",
      "BLEU Reward: 0.455\n",
      "Loss: 0.033\n",
      "------------------------------------------------------------\n",
      "JA: 世阿弥『俊寛 (能)』...\n",
      "Generated: Sei\n",
      "Reference: Zeami \"Shunkan\" (Noh program)\n",
      "BLEU Reward: 0.414\n",
      "Loss: 0.114\n",
      "------------------------------------------------------------\n",
      "Average Loss: 0.0736\n",
      "\n",
      "--- RL Step 8/100 ---\n",
      "JA: 能円...\n",
      "Generated: Noh\n",
      "Reference: Noen\n",
      "BLEU Reward: 0.432\n",
      "Loss: 0.005\n",
      "------------------------------------------------------------\n",
      "JA: 南泉門下。...\n",
      "Generated: South泉 Gate.\n",
      "Reference: Volume 10 covers disciples of Nansen.\n",
      "BLEU Reward: 0.432\n",
      "Loss: 0.427\n",
      "------------------------------------------------------------\n",
      "Average Loss: 0.2159\n",
      "\n",
      "--- RL Step 9/100 ---\n",
      "JA: 本末制度（ほんまつせいど）は、江戸時代、徳川幕府が仏教教団を統制するために設けた制度である。...\n",
      "Generated: The Honmatsu system.\n",
      "Reference: \"Honmatsu seido,\" a system intended to control the Buddhist organizations, was established by the Tokugawa shogunate during the Edo period.\n",
      "BLEU Reward: 0.445\n",
      "Loss: 0.010\n",
      "------------------------------------------------------------\n",
      "JA: 横笛は都へ帰る途中、自分の気持ちを伝えたく、近くの石に「山深み 思い入りぬる柴の戸の まことの道に我...\n",
      "Generated: On his way back to the capital, Yokobe cut his finger on the nearby stone, and wrote it in the blood.\n",
      "Reference: It is said that on her way home, Yokobue cut her finger and wrote in blood the following elegy on a stone, hoping that Tokiyori would know her feelings: Deep in the mountains, Feel restless and visit a shack, Hope the gate will guide me, To the true path.\n",
      "BLEU Reward: 0.446\n",
      "Loss: 0.070\n",
      "------------------------------------------------------------\n",
      "Average Loss: 0.0400\n",
      "\n",
      "--- RL Step 10/100 ---\n",
      "JA: 7月　七月七日の七夕...\n",
      "Generated: July, July.\n",
      "Reference: July: Tanabata (Festival of the Weaver) on July 7\n",
      "BLEU Reward: 0.446\n",
      "Loss: 0.015\n",
      "------------------------------------------------------------\n",
      "JA: 正定聚に住するがゆゑに、かならず滅度に至る。...\n",
      "Generated: It lived in Shoto.\n",
      "Reference: Because they live among the truly settled, they attain nirvana.\n",
      "BLEU Reward: 0.439\n",
      "Loss: 0.179\n",
      "------------------------------------------------------------\n",
      "Average Loss: 0.0971\n",
      "\n",
      "--- RL Step 11/100 ---\n",
      "JA: 正定聚に住するがゆゑに、かならず滅度に至る。...\n",
      "Generated: They lived in Shoto.\n",
      "Reference: Because they live among the truly settled, they attain nirvana.\n",
      "BLEU Reward: 0.439\n",
      "Loss: 0.271\n",
      "------------------------------------------------------------\n",
      "JA: 中巻18話は本朝の高僧伝などで、内17話までが『日本霊異記』からの引用。...\n",
      "Generated: The middle volume is cited in the Shinto.\n",
      "Reference: 18 tales in the second volume are biographies of high-rank monks of that imperial reign and 17 of them have been cited from \"Nihon Ryoiki\" (Miraculous Stories from the Japanese Buddhist Tradition, written in the early Heian period).\n",
      "BLEU Reward: 0.436\n",
      "Loss: 0.460\n",
      "------------------------------------------------------------\n",
      "Average Loss: 0.3654\n",
      "\n",
      "--- RL Step 12/100 ---\n",
      "JA: 通称、紫宸殿御本尊（ししんでんごほんぞん）と呼ばれるものは、富士大石寺と京都要法寺にある本尊である。...\n",
      "Generated: It is called Shinto.\n",
      "Reference: Normally, Shishinden-gohonzon is the name of the Honzon in Fuji Taiseki-ji Temple and Kyoto Yobo-ji Temple.\n",
      "BLEU Reward: 0.423\n",
      "Loss: 0.313\n",
      "------------------------------------------------------------\n",
      "JA: 帰国後、最澄は桓武天皇に対し従来の六宗に加え、新たに法華宗を独立した宗派として公認されるよう奏請、天...\n",
      "Generated: After he returned to his country, Saicho asked the Emperor Kanmu to be admitted as an independent sect.\n",
      "Reference: After coming back to Japan, Saicho petitioned the Emperor Kanmu to publicly approve Hokke sect as a newly independent school in addition to the traditional six sects, and after the Emperor died, he petitioned for a new assignment of nenbundo-sha and asked to add two priests in Tendai sect (one in Shana-gyo and one in Shikango (Meditation Course), respectively) as well as Nanto rokushu.\n",
      "BLEU Reward: 0.445\n",
      "Loss: 0.146\n",
      "------------------------------------------------------------\n",
      "Average Loss: 0.2297\n",
      "\n",
      "--- RL Step 13/100 ---\n",
      "JA: 浄土寺...\n",
      "Generated: Jodo\n",
      "Reference: Jodo-ji Temple\n",
      "BLEU Reward: 0.429\n",
      "Loss: 0.080\n",
      "------------------------------------------------------------\n",
      "JA: 仏壇を処分する際には「正念抜き」をする。...\n",
      "Generated: When disposing of the Buddhist altar.\n",
      "Reference: In the event of disposal of butsudan, 'shonen-nuki' (withdrawal of life) from butsuzo, hanging scroll and ihai is required.\n",
      "BLEU Reward: 0.431\n",
      "Loss: 0.031\n",
      "------------------------------------------------------------\n",
      "Average Loss: 0.0557\n",
      "\n",
      "--- RL Step 14/100 ---\n",
      "JA: この後者の事相部の著述については真偽両説がある。...\n",
      "Generated: There are two theories about the writing of the latter.\n",
      "Reference: Concerning these literary works included in the category of the theoretical parts, there are two contradictory views on their authenticity.\n",
      "BLEU Reward: 0.458\n",
      "Loss: 0.029\n",
      "------------------------------------------------------------\n",
      "JA: 『三宝院賢俊像』は醍醐寺所蔵、また『三宝院賢俊僧正日記』がある。...\n",
      "Generated: The \"Sanboin Kentosho.\"\n",
      "Reference: In addition to \"The portrait of Sanpoin Kenshun\" owned by Daigo-ji Temple, \"Sanpoin Kenshun Sojo Nikki\" (Diary of Kenshun, Sanpoin Temple) is left.\n",
      "BLEU Reward: 0.431\n",
      "Loss: 0.076\n",
      "------------------------------------------------------------\n",
      "Average Loss: 0.0524\n",
      "\n",
      "--- RL Step 15/100 ---\n",
      "JA: 日親（にっしん、1407年（応永14年） - 1488年10月21日（長享2年9月17日 (旧暦)）...\n",
      "Generated: Nichien.\n",
      "Reference: Nisshin (1407 - October 30, 1488) was a priest of the Nichiren Sect in the Muromachi period.\n",
      "BLEU Reward: 0.409\n",
      "Loss: 0.244\n",
      "------------------------------------------------------------\n",
      "JA: 俊芿に帰依した宇都宮信房に仙遊寺を寄進され、寺号を泉涌寺と改めて再興するための勧進を行った。...\n",
      "Generated: He donated Senyu-ji to Nobu.\n",
      "Reference: Nobufusa UTSUNOMIYA, who became a Buddhist thanks to Shunjo, donated Senyu-ji Temple to him, and Shunjo changed the Chinese characters used for its name and fundraised for the re-construction of the temple.\n",
      "BLEU Reward: 0.437\n",
      "Loss: 0.028\n",
      "------------------------------------------------------------\n",
      "Average Loss: 0.1364\n",
      "\n",
      "--- RL Step 16/100 ---\n",
      "JA: 僧尼令（そうにりょう）とは、日本律令法に設けられた編目の1つ。...\n",
      "Generated: Soni.\n",
      "Reference: Soniryo was a division of the Japanese ritsuryo code.\n",
      "BLEU Reward: 0.424\n",
      "Loss: 0.049\n",
      "------------------------------------------------------------\n",
      "JA: これを「薫の聖教（かおりのしょうぎょう）」という。...\n",
      "Generated: It was called 'Kaoru's Shinto.'\n",
      "Reference: This is what is called 'Kaori no Shogyo' (the fragrant scriptures).\n",
      "BLEU Reward: 0.453\n",
      "Loss: 0.028\n",
      "------------------------------------------------------------\n",
      "Average Loss: 0.0386\n",
      "\n",
      "--- RL Step 17/100 ---\n",
      "JA: 世阿弥『俊寛 (能)』...\n",
      "Generated: Sei\n",
      "Reference: Zeami \"Shunkan\" (Noh program)\n",
      "BLEU Reward: 0.414\n",
      "Loss: 0.021\n",
      "------------------------------------------------------------\n",
      "JA: 少なくとも、出自と無関係な家紋（それも2種類）の使用、すなわち詐称を天海ほどの高僧が行うとは思えない...\n",
      "Generated: At least, it was not thought to be done by a priest.\n",
      "Reference: At least, it is doubtful that a high priest like Tenkai used family crests (even two types) that are not related to his origin.\n",
      "BLEU Reward: 0.451\n",
      "Loss: 0.133\n",
      "------------------------------------------------------------\n",
      "Average Loss: 0.0768\n",
      "\n",
      "--- RL Step 18/100 ---\n",
      "JA: インド呪術は、僊那から日本僧の弟子へ伝授された。...\n",
      "Generated: The Indian magic was imparted to a Japanese priest.\n",
      "Reference: The Indian occult art was taught from Senna to his Japanese disciples.\n",
      "BLEU Reward: 0.469\n",
      "Loss: 0.054\n",
      "------------------------------------------------------------\n",
      "JA: 仏具の例...\n",
      "Generated: Buddhist instruments\n",
      "Reference: Examples of Butsugu\n",
      "BLEU Reward: 0.427\n",
      "Loss: 0.178\n",
      "------------------------------------------------------------\n",
      "Average Loss: 0.1160\n",
      "\n",
      "--- RL Step 19/100 ---\n",
      "JA: 江戸時代には虚無僧の集団が形成された特殊な宗派であった。...\n",
      "Generated: It was a special sect.\n",
      "Reference: In the Edo period, Fuke sect was a special religious school that was formed by group of komuso.\n",
      "BLEU Reward: 0.444\n",
      "Loss: 0.007\n",
      "------------------------------------------------------------\n",
      "JA: しかし、仏教の中心であった長安の方が写経のたびに改編され、テキストとして洗練の度を加えていったため、...\n",
      "Generated: However, there is a theory that the Chochi text, which was the center of Buddhism, was adapted every time in the sutra.\n",
      "Reference: However, another theory asserts that the edition of Choan, the center of Buddhism, had been reformed with each collection of manuscripts and became sophisticated as a text, so that the Shu edition of the local version has kept the original form adversely.\n",
      "BLEU Reward: 0.454\n",
      "Loss: 0.138\n",
      "------------------------------------------------------------\n",
      "Average Loss: 0.0729\n",
      "\n",
      "--- RL Step 20/100 ---\n",
      "JA: 1658年（万治元年）ごろ京都白川照高院に移って照高院門跡となり堂宇を復興した。...\n",
      "Generated: It was rebuilt.\n",
      "Reference: In 1658, he transferred to Shokoin Temple in Shirakawa, Kyoto and assumed the position of chief priest of Shokoin Temple and restored a temple building.\n",
      "BLEU Reward: 0.430\n",
      "Loss: 0.138\n",
      "------------------------------------------------------------\n",
      "JA: 805年（延暦24年）桓武天皇の病気平癒を祈願し、翌806年（延暦25年）大僧都に任じられたが玄賓は...\n",
      "Generated: In 805, he prayed for the disease to be cured.\n",
      "Reference: In 805, he prayed for Emperor Kanmu's recovery from illness, and in 806, Genpin was appointed as Daisozu (the highest grade that can be held by one who has reached the second highest rank in the hierarchy of Buddhist priests) but declined it.\n",
      "BLEU Reward: 0.446\n",
      "Loss: 0.111\n",
      "------------------------------------------------------------\n",
      "Average Loss: 0.1242\n",
      "\n",
      "--- RL Step 21/100 ---\n",
      "JA: 東京・浅草寺 ― 聖観音...\n",
      "Generated: Tokyo Asakusa\n",
      "Reference: Tokyo Senso-ji Temple - Sho Kannon\n",
      "BLEU Reward: 0.411\n",
      "Loss: 0.055\n",
      "------------------------------------------------------------\n",
      "JA: 訣別...\n",
      "Generated: Seen\n",
      "Reference: Farewell\n",
      "BLEU Reward: 0.440\n",
      "Loss: 0.611\n",
      "------------------------------------------------------------\n",
      "Average Loss: 0.3330\n",
      "\n",
      "--- RL Step 22/100 ---\n",
      "JA: 慈雲妙意...\n",
      "Generated: Mien\n",
      "Reference: Jiun-Myoi\n",
      "BLEU Reward: 0.389\n",
      "Loss: 0.121\n",
      "------------------------------------------------------------\n",
      "JA: 喉を枯らし飢えていたので、水や食べ物を差し出したが、ことごとく口に入る直前に炎となって、母親の口には...\n",
      "Generated: He was starving, and he gave her water and food, but it became a fire, and she did not enter her mother's mouth.\n",
      "Reference: Seeing that her throat was dry and she was hungry, he offered her water and food, but all of them caught fire before entering her mouth, and she could not eat or drink.\n",
      "BLEU Reward: 0.464\n",
      "Loss: 0.208\n",
      "------------------------------------------------------------\n",
      "Average Loss: 0.1646\n",
      "\n",
      "--- RL Step 23/100 ---\n",
      "JA: 862年（貞観_(日本)4年）真如法親王とともに唐へ渡った。...\n",
      "Generated: In 862.\n",
      "Reference: In the year 862, he travelled to Tang Dynasty China with Cloistered Imperial Prince Shinnyo.\n",
      "BLEU Reward: 0.435\n",
      "Loss: 0.024\n",
      "------------------------------------------------------------\n",
      "JA: 構成...\n",
      "Generated: Configuration\n",
      "Reference: Structure\n",
      "BLEU Reward: 0.504\n",
      "Loss: 0.003\n",
      "------------------------------------------------------------\n",
      "Average Loss: 0.0138\n",
      "\n",
      "--- RL Step 24/100 ---\n",
      "JA: 海門承朝...\n",
      "Generated: Sei\n",
      "Reference: Kaimon Shocho\n",
      "BLEU Reward: 0.417\n",
      "Loss: 0.031\n",
      "------------------------------------------------------------\n",
      "JA: 南泉門下。...\n",
      "Generated: South泉 Gate.\n",
      "Reference: Volume 10 covers disciples of Nansen.\n",
      "BLEU Reward: 0.432\n",
      "Loss: 0.012\n",
      "------------------------------------------------------------\n",
      "Average Loss: 0.0215\n",
      "\n",
      "--- RL Step 25/100 ---\n",
      "JA: そして、現在でも、この極楽で人々のために説法している。...\n",
      "Generated: And even now, I am preaching for people in this extreme.\n",
      "Reference: And even now, he preaches for people in this Gokuraku.\n",
      "BLEU Reward: 0.470\n",
      "Loss: 0.036\n",
      "------------------------------------------------------------\n",
      "JA: その結果、殺人・姦盗以外は仏教の戒律に基づいて処分することが認められた。...\n",
      "Generated: As a result, it was allowed to be disposed of.\n",
      "Reference: Consequently it became possible to apply the Buddhist precepts to the cases other than murder and theft.\n",
      "BLEU Reward: 0.439\n",
      "Loss: 0.026\n",
      "------------------------------------------------------------\n",
      "Average Loss: 0.0308\n",
      "\n",
      "--- RL Step 26/100 ---\n",
      "JA: 地域によっては、他宗の習慣同様に、線香を三等分になるように折る場合もある。...\n",
      "Generated: In some regions, as in other sects.\n",
      "Reference: Depending on the region, an incense stick is broken into three pieces like the practice in other sects.\n",
      "BLEU Reward: 0.445\n",
      "Loss: 0.040\n",
      "------------------------------------------------------------\n",
      "JA: 帰国後、最澄は桓武天皇に対し従来の六宗に加え、新たに法華宗を独立した宗派として公認されるよう奏請、天...\n",
      "Generated: After he returned to his country, Sai asked the Emperor Kanmu to be admitted as an independent sect.\n",
      "Reference: After coming back to Japan, Saicho petitioned the Emperor Kanmu to publicly approve Hokke sect as a newly independent school in addition to the traditional six sects, and after the Emperor died, he petitioned for a new assignment of nenbundo-sha and asked to add two priests in Tendai sect (one in Shana-gyo and one in Shikango (Meditation Course), respectively) as well as Nanto rokushu.\n",
      "BLEU Reward: 0.442\n",
      "Loss: 0.203\n",
      "------------------------------------------------------------\n",
      "Average Loss: 0.1215\n",
      "\n",
      "--- RL Step 27/100 ---\n",
      "JA: 「座禅」とも表記されるが、正式には「坐」の字を使用する。...\n",
      "Generated: It is also written as 'za.'\n",
      "Reference: It is sometimes written with the characters 座禅 however it is correct to use the character 坐.\n",
      "BLEU Reward: 0.431\n",
      "Loss: 0.057\n",
      "------------------------------------------------------------\n",
      "JA: 地域によっては、他宗の習慣同様に、線香を三等分になるように折る場合もある。...\n",
      "Generated: In some regions, as in other sects.\n",
      "Reference: Depending on the region, an incense stick is broken into three pieces like the practice in other sects.\n",
      "BLEU Reward: 0.445\n",
      "Loss: 0.047\n",
      "------------------------------------------------------------\n",
      "Average Loss: 0.0525\n",
      "\n",
      "--- RL Step 28/100 ---\n",
      "JA: 海門承朝...\n",
      "Generated: Sei\n",
      "Reference: Kaimon Shocho\n",
      "BLEU Reward: 0.417\n",
      "Loss: 0.006\n",
      "------------------------------------------------------------\n",
      "JA: 行者には、次の意味がある。...\n",
      "Generated: The line has the following meaning.\n",
      "Reference: Gyoja or Anja has the following meanings.\n",
      "BLEU Reward: 0.451\n",
      "Loss: 0.015\n",
      "------------------------------------------------------------\n",
      "Average Loss: 0.0104\n",
      "\n",
      "--- RL Step 29/100 ---\n",
      "JA: 高野山宗教舞踊会総司所...\n",
      "Generated: Koen\n",
      "Reference: Administration Office of Koyasan Religious Buyo dance (dance to the rhythm of Goeika)\n",
      "BLEU Reward: 0.415\n",
      "Loss: 0.042\n",
      "------------------------------------------------------------\n",
      "JA: しかしながら、康暦の政変で頼之が失脚すると外された。...\n",
      "Generated: However, he was expelled.\n",
      "Reference: However, the gozan status of Rinsen-ji Temple was removed when Yoriyuki lost his governmental position due to the Koryaku Coup.\n",
      "BLEU Reward: 0.441\n",
      "Loss: 0.043\n",
      "------------------------------------------------------------\n",
      "Average Loss: 0.0425\n",
      "\n",
      "--- RL Step 30/100 ---\n",
      "JA: 一遍の弟子他阿真教の徒弟として、正応4年（1291年）に京都錦小路通に歓喜光寺を建てた。...\n",
      "Generated: In 1291, he built Kai.\n",
      "Reference: As an apprentice of Taa, who was a disciple of Ippen, Jokai built the Kankiko-ji Temple along the Nishikikoji-dori Street, Kyoto, in 1291.\n",
      "BLEU Reward: 0.440\n",
      "Loss: 0.215\n",
      "------------------------------------------------------------\n",
      "JA: 信者は、既存の寺の教えを表法と呼び、隠し念仏の教えを内法（内信心）と呼んでいる。...\n",
      "Generated: The believers called the teachings of the existing temples.\n",
      "Reference: The believers call the existing teachings of a temple the outward law, and call the teachings of kakushi nenbutsu the inward law (or the inward belief).\n",
      "BLEU Reward: 0.449\n",
      "Loss: 0.012\n",
      "------------------------------------------------------------\n",
      "Average Loss: 0.1135\n",
      "\n",
      "--- RL Step 31/100 ---\n",
      "JA: 「座禅」とも表記されるが、正式には「坐」の字を使用する。...\n",
      "Generated: It is also called 'za.'\n",
      "Reference: It is sometimes written with the characters 座禅 however it is correct to use the character 坐.\n",
      "BLEU Reward: 0.424\n",
      "Loss: 0.066\n",
      "------------------------------------------------------------\n",
      "JA: 南泉門下。...\n",
      "Generated: South泉 Gate.\n",
      "Reference: Volume 10 covers disciples of Nansen.\n",
      "BLEU Reward: 0.432\n",
      "Loss: 0.021\n",
      "------------------------------------------------------------\n",
      "Average Loss: 0.0436\n",
      "\n",
      "--- RL Step 32/100 ---\n",
      "JA: いずれも江戸時代までには軍事力を喪失するか、分割されるなどして宗教と軍事力が切り離されている。...\n",
      "Generated: By the Edo period, religion was separated.\n",
      "Reference: Since all temples and shrines mentioned above had either lost their military power or had been divided, their religious powers had been separated from the military powers by the Edo period.\n",
      "BLEU Reward: 0.455\n",
      "Loss: 0.092\n",
      "------------------------------------------------------------\n",
      "JA: 七高僧…称名念仏の教えを説き示し、受け伝えた高僧として、以下の7人を選定した。...\n",
      "Generated: The seven high priests.\n",
      "Reference: The Seven Patriarchs of Jodo Shinshu: Shinran selected the following 7 monks as the high priests who had taught and spread the doctrine of Shomyo Nenbutsu.\n",
      "BLEU Reward: 0.447\n",
      "Loss: 0.159\n",
      "------------------------------------------------------------\n",
      "Average Loss: 0.1256\n",
      "\n",
      "--- RL Step 33/100 ---\n",
      "JA: 高野山宗教舞踊会総司所...\n",
      "Generated: Koen\n",
      "Reference: Administration Office of Koyasan Religious Buyo dance (dance to the rhythm of Goeika)\n",
      "BLEU Reward: 0.415\n",
      "Loss: 0.004\n",
      "------------------------------------------------------------\n",
      "JA: 法然が黒田の聖人に宛てた消息（手紙）であり、『黒谷上人語灯録』『西方指南抄』などに収録されている。...\n",
      "Generated: It was a message to a priest in Kurota.\n",
      "Reference: It is a shosoku (letter) from Honen to Kuroda no shonin, which is included in \"Kurodani Shonin Gotoroku\" and \"Saiho shinan sho.\"\n",
      "BLEU Reward: 0.431\n",
      "Loss: 0.117\n",
      "------------------------------------------------------------\n",
      "Average Loss: 0.0604\n",
      "\n",
      "--- RL Step 34/100 ---\n",
      "JA: 滋賀院（しがいん）は、滋賀県大津市坂本 (大津市)にある天台宗の寺院で比叡山延暦寺の本坊（総里坊）で...\n",
      "Generated: Shigain.\n",
      "Reference: Shiga-in Temple, a temple of the Tendai sect located in Sakamoto, Otsu City, Shiga Prefecture, s a honbo (a priest's main living quarters) (Sosatobo) of Enryaku-ji Temple on Mt. Hiei.\n",
      "BLEU Reward: 0.399\n",
      "Loss: 0.009\n",
      "------------------------------------------------------------\n",
      "JA: これに土をかぶせる。...\n",
      "Generated: I put the soil.\n",
      "Reference: Next, covered it up with clay soil.\n",
      "BLEU Reward: 0.463\n",
      "Loss: 0.147\n",
      "------------------------------------------------------------\n",
      "Average Loss: 0.0779\n",
      "\n",
      "--- RL Step 35/100 ---\n",
      "JA: 1658年（万治元年）ごろ京都白川照高院に移って照高院門跡となり堂宇を復興した。...\n",
      "Generated: It was rebuilt.\n",
      "Reference: In 1658, he transferred to Shokoin Temple in Shirakawa, Kyoto and assumed the position of chief priest of Shokoin Temple and restored a temple building.\n",
      "BLEU Reward: 0.430\n",
      "Loss: 0.010\n",
      "------------------------------------------------------------\n",
      "JA: 能円...\n",
      "Generated: Noh\n",
      "Reference: Noen\n",
      "BLEU Reward: 0.432\n",
      "Loss: 0.035\n",
      "------------------------------------------------------------\n",
      "Average Loss: 0.0226\n",
      "\n",
      "--- RL Step 36/100 ---\n",
      "JA: 俊芿に帰依した宇都宮信房に仙遊寺を寄進され、寺号を泉涌寺と改めて再興するための勧進を行った。...\n",
      "Generated: He donated Sen.\n",
      "Reference: Nobufusa UTSUNOMIYA, who became a Buddhist thanks to Shunjo, donated Senyu-ji Temple to him, and Shunjo changed the Chinese characters used for its name and fundraised for the re-construction of the temple.\n",
      "BLEU Reward: 0.419\n",
      "Loss: 0.114\n",
      "------------------------------------------------------------\n",
      "JA: 僧尼令（そうにりょう）とは、日本律令法に設けられた編目の1つ。...\n",
      "Generated: Soni.\n",
      "Reference: Soniryo was a division of the Japanese ritsuryo code.\n",
      "BLEU Reward: 0.424\n",
      "Loss: 0.036\n",
      "------------------------------------------------------------\n",
      "Average Loss: 0.0753\n",
      "\n",
      "--- RL Step 37/100 ---\n",
      "JA: 正定聚に住するがゆゑに、かならず滅度に至る。...\n",
      "Generated: They lived in Sho.\n",
      "Reference: Because they live among the truly settled, they attain nirvana.\n",
      "BLEU Reward: 0.439\n",
      "Loss: 0.077\n",
      "------------------------------------------------------------\n",
      "JA: 実名は兼祐、幼名は光養。...\n",
      "Generated: His real name was.\n",
      "Reference: Renko's real name was Kenyu and his childhood name Koyo.\n",
      "BLEU Reward: 0.444\n",
      "Loss: 0.101\n",
      "------------------------------------------------------------\n",
      "Average Loss: 0.0891\n",
      "\n",
      "--- RL Step 38/100 ---\n",
      "JA: 願名…聞名得忍の願...\n",
      "Generated: the wish\n",
      "Reference: Title: Monmyotokunin no gan\n",
      "BLEU Reward: 0.403\n",
      "Loss: 0.219\n",
      "------------------------------------------------------------\n",
      "JA: 通称、紫宸殿御本尊（ししんでんごほんぞん）と呼ばれるものは、富士大石寺と京都要法寺にある本尊である。...\n",
      "Generated: It is called Shin.\n",
      "Reference: Normally, Shishinden-gohonzon is the name of the Honzon in Fuji Taiseki-ji Temple and Kyoto Yobo-ji Temple.\n",
      "BLEU Reward: 0.425\n",
      "Loss: 0.006\n",
      "------------------------------------------------------------\n",
      "Average Loss: 0.1126\n",
      "\n",
      "--- RL Step 39/100 ---\n",
      "JA: 構成...\n",
      "Generated: Configuration\n",
      "Reference: Structure\n",
      "BLEU Reward: 0.504\n",
      "Loss: 0.004\n",
      "------------------------------------------------------------\n",
      "JA: 通称、紫宸殿御本尊（ししんでんごほんぞん）と呼ばれるものは、富士大石寺と京都要法寺にある本尊である。...\n",
      "Generated: It is called Shin.\n",
      "Reference: Normally, Shishinden-gohonzon is the name of the Honzon in Fuji Taiseki-ji Temple and Kyoto Yobo-ji Temple.\n",
      "BLEU Reward: 0.425\n",
      "Loss: 0.010\n",
      "------------------------------------------------------------\n",
      "Average Loss: 0.0067\n",
      "\n",
      "--- RL Step 40/100 ---\n",
      "JA: 「善行人地大先去故身静。」...\n",
      "Generated: 'Good people go.'\n",
      "Reference: One with good nature always has temperament of great earth, so one's body is quiet.'\n",
      "BLEU Reward: 0.434\n",
      "Loss: 0.163\n",
      "------------------------------------------------------------\n",
      "JA: 巻7に至り、一切の法は道理であり其の道理に基づいて世の直し方の方法を論述している。...\n",
      "Generated: Until Volume 7.\n",
      "Reference: In volume 7 he described that everything was based on Dori and that the way to reform society should be implemented by Dori.\n",
      "BLEU Reward: 0.452\n",
      "Loss: 0.252\n",
      "------------------------------------------------------------\n",
      "Average Loss: 0.2075\n",
      "\n",
      "--- RL Step 41/100 ---\n",
      "JA: 定慧、貞恵とも書かれる。...\n",
      "Generated: It is called.\n",
      "Reference: His name is written alternatively as 定慧 or 貞恵 as well.\n",
      "BLEU Reward: 0.415\n",
      "Loss: 0.029\n",
      "------------------------------------------------------------\n",
      "JA: 中巻18話は本朝の高僧伝などで、内17話までが『日本霊異記』からの引用。...\n",
      "Generated: The middle volume is cited in the Shinto.\n",
      "Reference: 18 tales in the second volume are biographies of high-rank monks of that imperial reign and 17 of them have been cited from \"Nihon Ryoiki\" (Miraculous Stories from the Japanese Buddhist Tradition, written in the early Heian period).\n",
      "BLEU Reward: 0.436\n",
      "Loss: 0.325\n",
      "------------------------------------------------------------\n",
      "Average Loss: 0.1768\n",
      "\n",
      "--- RL Step 42/100 ---\n",
      "JA: 院尊（法印）...\n",
      "Generated: In\n",
      "Reference: Inson (Hoin)\n",
      "BLEU Reward: 0.429\n",
      "Loss: 0.009\n",
      "------------------------------------------------------------\n",
      "JA: 然る間、去年窮冬下旬八日、図らざるに火あり。...\n",
      "Generated: Meanwhile, last winter.\n",
      "Reference: Meanwhile, a fire broke out in the city of Nara on the eighth of December (old lunar calendar) last year.\n",
      "BLEU Reward: 0.447\n",
      "Loss: 0.066\n",
      "------------------------------------------------------------\n",
      "Average Loss: 0.0377\n",
      "\n",
      "--- RL Step 43/100 ---\n",
      "JA: 日親（にっしん、1407年（応永14年） - 1488年10月21日（長享2年9月17日 (旧暦)）...\n",
      "Generated: Nichien.\n",
      "Reference: Nisshin (1407 - October 30, 1488) was a priest of the Nichiren Sect in the Muromachi period.\n",
      "BLEU Reward: 0.409\n",
      "Loss: 0.108\n",
      "------------------------------------------------------------\n",
      "JA: 「善行人地大先去故身静。」...\n",
      "Generated: 'Good people go.'\n",
      "Reference: One with good nature always has temperament of great earth, so one's body is quiet.'\n",
      "BLEU Reward: 0.434\n",
      "Loss: 0.080\n",
      "------------------------------------------------------------\n",
      "Average Loss: 0.0939\n",
      "\n",
      "--- RL Step 44/100 ---\n",
      "JA: だが、嘉吉の変で義教が暗殺されると、大和国の越智氏・古市氏らの支援を受けて已心寺に入り、活動を再開す...\n",
      "Generated: However, when Yoshin was assassinated.\n",
      "Reference: However, after Yoshimichi was assassinated in the Kakitsu Incident, Kyokaku obtained support from the Ochi and Furuichi clans of Yamato Province and entered 已心寺, becoming politically active once more.\n",
      "BLEU Reward: 0.440\n",
      "Loss: 0.027\n",
      "------------------------------------------------------------\n",
      "JA: 世阿弥『俊寛 (能)』...\n",
      "Generated: Sei\n",
      "Reference: Zeami \"Shunkan\" (Noh program)\n",
      "BLEU Reward: 0.414\n",
      "Loss: 0.003\n",
      "------------------------------------------------------------\n",
      "Average Loss: 0.0150\n",
      "\n",
      "--- RL Step 45/100 ---\n",
      "JA: 史跡...\n",
      "Generated: Historical sites\n",
      "Reference: Historic Sites\n",
      "BLEU Reward: 0.486\n",
      "Loss: 0.010\n",
      "------------------------------------------------------------\n",
      "JA: 禅宗では法嗣といい、釈迦 - 摩訶迦葉へと伝えられた教外別伝の法を、代々受け継いだ付法蔵の第28祖が...\n",
      "Generated: In the Zen sect.\n",
      "Reference: It is called Hoshi in the Zen Sect, in which they claim that it was Daruma who was the twenty-eighth founder of fuhozo (those who, after Shakyamuni Buddha's death, successively inherited the lineage of his teachings and propagated them in India) that succeeded the Kyogai betsuden teaching (transmission of spiritual awakening without words or characters, but in a heart-to-heart way) from Shakamuni to Makakasho, through intuitive discernment from generation to generation.\n",
      "BLEU Reward: 0.429\n",
      "Loss: 0.058\n",
      "------------------------------------------------------------\n",
      "Average Loss: 0.0339\n",
      "\n",
      "--- RL Step 46/100 ---\n",
      "JA: 805年（延暦24年）桓武天皇の病気平癒を祈願し、翌806年（延暦25年）大僧都に任じられたが玄賓は...\n",
      "Generated: In 805.\n",
      "Reference: In 805, he prayed for Emperor Kanmu's recovery from illness, and in 806, Genpin was appointed as Daisozu (the highest grade that can be held by one who has reached the second highest rank in the hierarchy of Buddhist priests) but declined it.\n",
      "BLEU Reward: 0.422\n",
      "Loss: 0.010\n",
      "------------------------------------------------------------\n",
      "JA: 通夜は本来、夜通しで行うとされるが最近では夜6時ごろから9時ごろまで一般の参列者を招き僧侶の読経も1...\n",
      "Generated: It was originally done in the night.\n",
      "Reference: Tsuya were traditionally held throughout the night, but in modern times they are usually shortened to a half-tsuya, which is held from around six to nine pm, open to all mourners and having the priest reading from the Buddhist script only once.\n",
      "BLEU Reward: 0.435\n",
      "Loss: 0.194\n",
      "------------------------------------------------------------\n",
      "Average Loss: 0.1019\n",
      "\n",
      "--- RL Step 47/100 ---\n",
      "JA: 定慧、貞恵とも書かれる。...\n",
      "Generated: It is called.\n",
      "Reference: His name is written alternatively as 定慧 or 貞恵 as well.\n",
      "BLEU Reward: 0.415\n",
      "Loss: 0.004\n",
      "------------------------------------------------------------\n",
      "JA: 信者は、既存の寺の教えを表法と呼び、隠し念仏の教えを内法（内信心）と呼んでいる。...\n",
      "Generated: The believers called the teachings of the existing temples.\n",
      "Reference: The believers call the existing teachings of a temple the outward law, and call the teachings of kakushi nenbutsu the inward law (or the inward belief).\n",
      "BLEU Reward: 0.449\n",
      "Loss: 0.022\n",
      "------------------------------------------------------------\n",
      "Average Loss: 0.0130\n",
      "\n",
      "--- RL Step 48/100 ---\n",
      "JA: しかし、仏教の中心であった長安の方が写経のたびに改編され、テキストとして洗練の度を加えていったため、...\n",
      "Generated: However, there is a theory that the Shu text.\n",
      "Reference: However, another theory asserts that the edition of Choan, the center of Buddhism, had been reformed with each collection of manuscripts and became sophisticated as a text, so that the Shu edition of the local version has kept the original form adversely.\n",
      "BLEU Reward: 0.439\n",
      "Loss: 0.216\n",
      "------------------------------------------------------------\n",
      "JA: 世阿弥『俊寛 (能)』...\n",
      "Generated: Sei\n",
      "Reference: Zeami \"Shunkan\" (Noh program)\n",
      "BLEU Reward: 0.414\n",
      "Loss: 0.006\n",
      "------------------------------------------------------------\n",
      "Average Loss: 0.1113\n",
      "\n",
      "--- RL Step 49/100 ---\n",
      "JA: そして、現在でも、この極楽で人々のために説法している。...\n",
      "Generated: And even now, I am preaching for people in this extreme.\n",
      "Reference: And even now, he preaches for people in this Gokuraku.\n",
      "BLEU Reward: 0.470\n",
      "Loss: 0.038\n",
      "------------------------------------------------------------\n",
      "JA: 山号は葉室山。...\n",
      "Generated: The mountain name.\n",
      "Reference: Its sango (literally, \"mountain name\"), which is the title prefixed to the name of a Buddhist temple, is Hamurosan.\n",
      "BLEU Reward: 0.441\n",
      "Loss: 0.382\n",
      "------------------------------------------------------------\n",
      "Average Loss: 0.2103\n",
      "\n",
      "--- RL Step 50/100 ---\n",
      "JA: 構成...\n",
      "Generated: Configuration\n",
      "Reference: Structure\n",
      "BLEU Reward: 0.504\n",
      "Loss: 0.003\n",
      "------------------------------------------------------------\n",
      "JA: 巻7に至り、一切の法は道理であり其の道理に基づいて世の直し方の方法を論述している。...\n",
      "Generated: Until Volume 7.\n",
      "Reference: In volume 7 he described that everything was based on Dori and that the way to reform society should be implemented by Dori.\n",
      "BLEU Reward: 0.452\n",
      "Loss: 0.017\n",
      "------------------------------------------------------------\n",
      "Average Loss: 0.0101\n",
      "\n",
      "--- RL Step 51/100 ---\n",
      "JA: 巻7に至り、一切の法は道理であり其の道理に基づいて世の直し方の方法を論述している。...\n",
      "Generated: Until Volume 7.\n",
      "Reference: In volume 7 he described that everything was based on Dori and that the way to reform society should be implemented by Dori.\n",
      "BLEU Reward: 0.452\n",
      "Loss: 0.010\n",
      "------------------------------------------------------------\n",
      "JA: 横笛は都へ帰る途中、自分の気持ちを伝えたく、近くの石に「山深み 思い入りぬる柴の戸の まことの道に我...\n",
      "Generated: On his way back to the capital, he wrote.\n",
      "Reference: It is said that on her way home, Yokobue cut her finger and wrote in blood the following elegy on a stone, hoping that Tokiyori would know her feelings: Deep in the mountains, Feel restless and visit a shack, Hope the gate will guide me, To the true path.\n",
      "BLEU Reward: 0.433\n",
      "Loss: 0.103\n",
      "------------------------------------------------------------\n",
      "Average Loss: 0.0566\n",
      "\n",
      "--- RL Step 52/100 ---\n",
      "JA: 喉を枯らし飢えていたので、水や食べ物を差し出したが、ことごとく口に入る直前に炎となって、母親の口には...\n",
      "Generated: He was starving.\n",
      "Reference: Seeing that her throat was dry and she was hungry, he offered her water and food, but all of them caught fire before entering her mouth, and she could not eat or drink.\n",
      "BLEU Reward: 0.444\n",
      "Loss: 0.237\n",
      "------------------------------------------------------------\n",
      "JA: 跋提河の春の浪哀声再び聞え、沙羅林の朝の雲憂色重て聳え、眼を戴いて天を迎げば、則ち白霧胸に塞りて散せ...\n",
      "Generated: The waves of the spring of the Tra.\n",
      "Reference: Walking on the riverbanks this spring, we hear people wailing among the camellia trees that stand in the heavy morning mist, and when we raise our eyes to the heavens we feel a mist of sadness clouding our hearts.\n",
      "BLEU Reward: 0.423\n",
      "Loss: 0.104\n",
      "------------------------------------------------------------\n",
      "Average Loss: 0.1705\n",
      "\n",
      "--- RL Step 53/100 ---\n",
      "JA: 日親（にっしん、1407年（応永14年） - 1488年10月21日（長享2年9月17日 (旧暦)）...\n",
      "Generated: Nichien.\n",
      "Reference: Nisshin (1407 - October 30, 1488) was a priest of the Nichiren Sect in the Muromachi period.\n",
      "BLEU Reward: 0.409\n",
      "Loss: 0.039\n",
      "------------------------------------------------------------\n",
      "JA: （業因）...\n",
      "Generated: (industry)\n",
      "Reference: (Behavior)\n",
      "BLEU Reward: 0.449\n",
      "Loss: 0.164\n",
      "------------------------------------------------------------\n",
      "Average Loss: 0.1015\n",
      "\n",
      "--- RL Step 54/100 ---\n",
      "JA: これに土をかぶせる。...\n",
      "Generated: I put the soil.\n",
      "Reference: Next, covered it up with clay soil.\n",
      "BLEU Reward: 0.463\n",
      "Loss: 0.012\n",
      "------------------------------------------------------------\n",
      "JA: だが、嘉吉の変で義教が暗殺されると、大和国の越智氏・古市氏らの支援を受けて已心寺に入り、活動を再開す...\n",
      "Generated: However, when Yoshin.\n",
      "Reference: However, after Yoshimichi was assassinated in the Kakitsu Incident, Kyokaku obtained support from the Ochi and Furuichi clans of Yamato Province and entered 已心寺, becoming politically active once more.\n",
      "BLEU Reward: 0.422\n",
      "Loss: 0.055\n",
      "------------------------------------------------------------\n",
      "Average Loss: 0.0336\n",
      "\n",
      "--- RL Step 55/100 ---\n",
      "JA: 構成...\n",
      "Generated: Configuration\n",
      "Reference: Structure\n",
      "BLEU Reward: 0.504\n",
      "Loss: 0.003\n",
      "------------------------------------------------------------\n",
      "JA: 高野山宗教舞踊会総司所...\n",
      "Generated: Koen\n",
      "Reference: Administration Office of Koyasan Religious Buyo dance (dance to the rhythm of Goeika)\n",
      "BLEU Reward: 0.415\n",
      "Loss: 0.377\n",
      "------------------------------------------------------------\n",
      "Average Loss: 0.1898\n",
      "\n",
      "--- RL Step 56/100 ---\n",
      "JA: 訣別...\n",
      "Generated: let's go.\n",
      "Reference: Farewell\n",
      "BLEU Reward: 0.430\n",
      "Loss: 0.409\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m batch_en \u001b[38;5;241m=\u001b[39m [y_train\u001b[38;5;241m.\u001b[39miloc[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m batch_indices]\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- RL Step \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_rl_steps\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 19\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mrl_training_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_RL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_ja\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_en\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[41], line 46\u001b[0m, in \u001b[0;36mrl_training_step\u001b[1;34m(model, tokenizer, batch_ja, batch_en_ref, optimizer)\u001b[0m\n\u001b[0;32m     44\u001b[0m generated_text \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(generated_ids, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     45\u001b[0m bleu_reward \u001b[38;5;241m=\u001b[39m compute_bleu_reward(generated_text, en_ref)\n\u001b[1;32m---> 46\u001b[0m bert_reward\u001b[38;5;241m=\u001b[39m\u001b[43mcompute_bert_reward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerated_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43men_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m reward\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m\u001b[38;5;241m*\u001b[39m bleu_reward \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.5\u001b[39m\u001b[38;5;241m*\u001b[39m bert_reward\n\u001b[0;32m     49\u001b[0m reward\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m(reward)\n",
      "Cell \u001b[1;32mIn[41], line 11\u001b[0m, in \u001b[0;36mcompute_bert_reward\u001b[1;34m(generated_text, reference_text)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_bert_reward\u001b[39m(generated_text, reference_text):\n\u001b[0;32m     10\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute semantic level Bert score as reward\"\"\"\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m     P, R, F1 \u001b[38;5;241m=\u001b[39m \u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mgenerated_text\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mreference_text\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlang\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43men\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F1\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\laran\\Home\\Documents\\code\\venv\\NLPvenv\\Lib\\site-packages\\bert_score\\score.py:123\u001b[0m, in \u001b[0;36mscore\u001b[1;34m(cands, refs, model_type, num_layers, verbose, idf, device, batch_size, nthreads, all_layers, lang, return_hash, rescale_with_baseline, baseline_path, use_fast_tokenizer)\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalculating scores...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    122\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m--> 123\u001b[0m all_preds \u001b[38;5;241m=\u001b[39m \u001b[43mbert_cos_score_idf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrefs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43midf_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mall_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ref_group_boundaries \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    136\u001b[0m     max_preds \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\laran\\Home\\Documents\\code\\venv\\NLPvenv\\Lib\\site-packages\\bert_score\\utils.py:619\u001b[0m, in \u001b[0;36mbert_cos_score_idf\u001b[1;34m(model, refs, hyps, tokenizer, idf_dict, verbose, batch_size, device, all_layers)\u001b[0m\n\u001b[0;32m    615\u001b[0m sen_batch \u001b[38;5;241m=\u001b[39m sentences[batch_start : batch_start \u001b[38;5;241m+\u001b[39m batch_size]\n\u001b[0;32m    616\u001b[0m embs, masks, padded_idf \u001b[38;5;241m=\u001b[39m get_bert_embedding(\n\u001b[0;32m    617\u001b[0m     sen_batch, model, tokenizer, idf_dict, device\u001b[38;5;241m=\u001b[39mdevice, all_layers\u001b[38;5;241m=\u001b[39mall_layers\n\u001b[0;32m    618\u001b[0m )\n\u001b[1;32m--> 619\u001b[0m embs \u001b[38;5;241m=\u001b[39m \u001b[43membs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    620\u001b[0m masks \u001b[38;5;241m=\u001b[39m masks\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[0;32m    621\u001b[0m padded_idf \u001b[38;5;241m=\u001b[39m padded_idf\u001b[38;5;241m.\u001b[39mcpu()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# application of RL optimization\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "model_RL=model\n",
    "\n",
    "batch_size = 2\n",
    "num_rl_steps = 100  # 10 steps, adapt to more if time\n",
    "\n",
    "losses = []\n",
    "\n",
    "print(\"Starting RL training\")\n",
    "print(\"#\"*20)\n",
    "\n",
    "for step in range(num_rl_steps):\n",
    "    batch_indices = random.sample(range(len(X_train[:100])), batch_size) # random batch\n",
    "    batch_ja = [X_train.iloc[i] for i in batch_indices]\n",
    "    batch_en = [y_train.iloc[i] for i in batch_indices]\n",
    "    \n",
    "    print(f\"\\n--- RL Step {step+1}/{num_rl_steps} ---\")\n",
    "    loss = rl_training_step(model_RL, tokenizer, batch_ja, batch_en, optimizer)\n",
    "    losses.append(loss)\n",
    "    print(f\"Average Loss: {loss:.4f}\")\n",
    "\n",
    "print(\"RL training completed\")\n",
    "print(\"#\"*20)\n",
    "\n",
    "plt.plot(range(1, len(losses)+1), losses, marker=\"o\")\n",
    "plt.xlabel(\"RL Step\")\n",
    "plt.ylabel(\"Average Loss\")\n",
    "plt.title(\"RL Training Loss\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa77a8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using sample 8 from test dataset\n",
      "Japanese: 当寺の実質的な開山は碧潭周皎であるが、碧潭は法兄である夢窓疎石を勧請開山としている。\n",
      "English reference: Although the actual kaisan (a temple founder as the first chief priest) of the temple was Hekitan Shuko, Hekitan treated Muso Soseki, his priest brother, as a kanjo kaizan.\n",
      "Model translation: The actual opening of the temple was Seitan.\n"
     ]
    }
   ],
   "source": [
    "sample_idx= 8\n",
    "test_ja=X_test.iloc[sample_idx]\n",
    "test_en_reference=y_test.iloc[sample_idx]\n",
    "\n",
    "inputs = tokenizer(test_ja, return_tensors=\"pt\").to(\"cuda\")\n",
    "outputs = model_RL.generate(**inputs, forced_bos_token_id=tokenizer.lang_code_to_id[\"en_XX\"])\n",
    "result_rl = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(f\"Using sample {sample_idx} from test dataset\")\n",
    "print(f\"Japanese: {test_ja}\")\n",
    "print(f\"English reference: {test_en_reference}\")\n",
    "print(f\"Model translation: {result_rl}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6276d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on 100 samples...\n",
      "\n",
      "Example 1:\n",
      "JA:  1917年（大正6年）勧学が追贈されている。\n",
      "REF: In 1917, he was promoted to Kangaku ranking after his death.\n",
      "GEN: In 1917.\n",
      "BLEU: 0.17, BERTScore F1: 0.897\n",
      "\n",
      "Example 2:\n",
      "JA:  それゆえに直日・直堂も、修行者も、両者ともが警策を「与える」・「いただく」前後に合掌低頭し、お互いに感謝の意を表わす。\n",
      "REF: Therefore, both of Jikijitsu or jikido and meditators make the gassho (place the palms of the hands together in the position of prayer) and bow their head to show their gratitude each other, before and after the keisaku (kyosaku) is to \"give\" and \"receive\".\n",
      "GEN: Therefore, on the first day, the Naido and the practitioners, both of them, lowered their hands and expressed their gratitude to each other.\n",
      "BLEU: 1.36, BERTScore F1: 0.873\n",
      "\n",
      "Example 3:\n",
      "JA:  古市 胤栄（ふるいち いんえい、生年不詳 - 永正2年（1505年））は、戦国時代 (日本)の僧・武将。\n",
      "REF: Ine FURUICHI (year of birth unknown - 1505) is a priest and a Japanese military commander during the Sengoku period.\n",
      "GEN: Taneie.\n",
      "BLEU: 0.00, BERTScore F1: 0.802\n",
      "\n",
      "Example 4:\n",
      "JA:  道忠自身は鑑真の弟子で、律宗の僧侶であったが、戒壇が設けられた下野薬師寺との関連か東国に住し、広く弟子を持つ僧侶であった。\n",
      "REF: Dochu himself was a disciple of Ganjin and a Buddhist priest in Ritsu sect, but he lived in Togoku maybe because he had a relationship with Shimotsuke Yakushi-ji Temple which had Kaidan (Buddhist ordination platform) and he had many disciples across a wide range.\n",
      "GEN: 道忠 himself was a priest of the Shinto sect.\n",
      "BLEU: 0.28, BERTScore F1: 0.857\n",
      "\n",
      "Example 5:\n",
      "JA:  つまり、律令体制下の仏教で国家の庇護を受けて仏教の研究を行い、宗教上の実践行為は鎮護国家という理念の下で呪術的な祈祷を行う程度であったといわれる。\n",
      "REF: In other words, they were the Buddhism under the Ritsuryo system; the priests of these sects were just scholars studying Buddhism under the protection of the nation, and as for actual religious activity, they just performed some magical prayers for the idea of Chingo-Kokka (guarding the nation by Buddhism).\n",
      "GEN: In other words, it is said that in Buddhism, under the Ritsuryo system, they studied Buddhism and performed magical prayers.\n",
      "BLEU: 2.19, BERTScore F1: 0.900\n"
     ]
    }
   ],
   "source": [
    "optimized_results = utils.evaluate_model(model_RL, tokenizer, X_test, y_test, max_samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5626fba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "post_optimization metrics\n",
      "####################\n",
      "Corpus BLEU: 1.68\n",
      "Corpus Bert: 0.87\n",
      "Average Sentence BLEU: 2.44 ± 5.28\n"
     ]
    }
   ],
   "source": [
    "print(\"post_optimization metrics\")\n",
    "print(\"#\"*20)\n",
    "print(f\"Corpus BLEU: {optimized_results['corpus_bleu']:.2f}\")\n",
    "print(f\"Corpus Bert: {optimized_results['corpus_bert']:.2f}\")\n",
    "print(f\"Average Sentence BLEU: {optimized_results['avg_sentence_bleu']:.2f} ± {optimized_results['std_sentence_bleu']:.2f}\")\n",
    "\n",
    "optimized_corpus_bleu=optimized_results['corpus_bleu']\n",
    "optimized_corpus_bert=optimized_results['corpus_bert']\n",
    "optimized_avg_bleu=optimized_results['avg_sentence_bleu'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11984547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus BLEU: 14.98\n",
      "Corpus Bert: 0.90\n",
      "Corpus BLEU: 1.68\n",
      "Corpus Bert: 0.87\n"
     ]
    }
   ],
   "source": [
    "print(f\"Corpus BLEU: {baseline_results['corpus_bleu']:.2f}\")\n",
    "print(f\"Corpus Bert: {baseline_results['corpus_bert']:.2f}\")\n",
    "\n",
    "print(f\"Corpus BLEU: {optimized_results['corpus_bleu']:.2f}\")\n",
    "print(f\"Corpus Bert: {optimized_results['corpus_bert']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36127245",
   "metadata": {},
   "source": [
    "# But how good are the transformers compared to old models?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17ba64b",
   "metadata": {},
   "source": [
    "## Example based Machine translation (EBMT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7847f119",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "80d5f36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(pairs, columns=[\"ja\", \"en\"]).dropna()   # dataframe and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b8ebf824",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['ja']   # original \n",
    "y = df['en']   # translated\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, \n",
    "    test_size=0.1,  # for the validation set\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cda7878f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ebmt_tfidf_baseline(X_train, y_train, X_test):\n",
    "    \"\"\"\n",
    "    Example-Based MT baseline using TF-IDF + nearest neighbor retrieval.\n",
    "    For each test sentence in Japanese, returns the English translation\n",
    "    of the most similar Japanese sentence from the training set.\n",
    "    \"\"\"\n",
    "    # Fit TF-IDF on Japanese training sentences\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "    \n",
    "    translations = []\n",
    "    for i in range(X_test_vec.shape[0]):\n",
    "        # Compute cosine similarity to all training sentences\n",
    "        sims = cosine_similarity(X_test_vec[i], X_train_vec).flatten()\n",
    "        # Pick the most similar training example\n",
    "        best_idx = np.argmax(sims)\n",
    "        translations.append(y_train.iloc[best_idx])\n",
    "    return translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ff624505",
   "metadata": {},
   "outputs": [],
   "source": [
    "ebmt_outputs = ebmt_tfidf_baseline(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a0e8e175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "JA: 1917年（大正6年）勧学が追贈されている。\n",
      "REF: In 1917, he was promoted to Kangaku ranking after his death.\n",
      "EBMT: Meanwhile, curtains were installed for the mural protection in 1917, and the murals were opened to the public only for a fixed viewing period in the spring and fall from the following year.\n",
      "\n",
      "JA: それゆえに直日・直堂も、修行者も、両者ともが警策を「与える」・「いただく」前後に合掌低頭し、お互いに感謝の意を表わす。\n",
      "REF: Therefore, both of Jikijitsu or jikido and meditators make the gassho (place the palms of the hands together in the position of prayer) and bow their head to show their gratitude each other, before and after the keisaku (kyosaku) is to \"give\" and \"receive\".\n",
      "EBMT: Gyoja or Anja has the following meanings.\n",
      "\n",
      "JA: 古市 胤栄（ふるいち いんえい、生年不詳 - 永正2年（1505年））は、戦国時代 (日本)の僧・武将。\n",
      "REF: Ine FURUICHI (year of birth unknown - 1505) is a priest and a Japanese military commander during the Sengoku period.\n",
      "EBMT: Choin FURUICHI (1452 - August 22, 1508) was a priest and busho (military commander) who lived in the Sengoku Period (Period of Warring States) in Japan.\n",
      "\n",
      "JA: 道忠自身は鑑真の弟子で、律宗の僧侶であったが、戒壇が設けられた下野薬師寺との関連か東国に住し、広く弟子を持つ僧侶であった。\n",
      "REF: Dochu himself was a disciple of Ganjin and a Buddhist priest in Ritsu sect, but he lived in Togoku maybe because he had a relationship with Shimotsuke Yakushi-ji Temple which had Kaidan (Buddhist ordination platform) and he had many disciples across a wide range.\n",
      "EBMT: Gyoja or Anja has the following meanings.\n",
      "\n",
      "JA: つまり、律令体制下の仏教で国家の庇護を受けて仏教の研究を行い、宗教上の実践行為は鎮護国家という理念の下で呪術的な祈祷を行う程度であったといわれる。\n",
      "REF: In other words, they were the Buddhism under the Ritsuryo system; the priests of these sects were just scholars studying Buddhism under the protection of the nation, and as for actual religious activity, they just performed some magical prayers for the idea of Chingo-Kokka (guarding the nation by Buddhism).\n",
      "EBMT: It means that it regards that there were only Hoshigo (kind of title bestowed to monks with high virtue) and Zenjigo (title given to master of Zen Buddhism) existing before that.\n"
     ]
    }
   ],
   "source": [
    "# Inspect a few examples\n",
    "for i in range(5):\n",
    "    print(f\"\\nJA: {X_test.iloc[i]}\")\n",
    "    print(f\"REF: {y_test.iloc[i]}\")\n",
    "    print(f\"EBMT: {ebmt_outputs[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0491b4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MT evaluation\n",
      "-----------------\n",
      "Corpus BLEU: 3.08\n",
      "Corpus BERTScore F1: 0.848\n",
      "EBMT SMT → BLEU: 3.08  |  BERTScore F1: 0.848\n"
     ]
    }
   ],
   "source": [
    "ebmt_bleu, ebmt_bert = utils.evaluate_mt(ebmt_outputs[:100], y_test[:100])\n",
    "print(f\"EBMT SMT → BLEU: {ebmt_bleu:.2f}  |  BERTScore F1: {ebmt_bert:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faee9eec",
   "metadata": {},
   "source": [
    "## Statistical machine translation (SMT, very minimal example implementation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "42d39add",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate import AlignedSent\n",
    "from nltk.translate.ibm2 import IBMModel2\n",
    "from collections import defaultdict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6bd1b908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ibm2(ja_texts, en_texts, n_sentences=2000, iterations=5):\n",
    "    \"\"\"\n",
    "    Train IBM Model 2 on a subset of the parallel data.\n",
    "    \"\"\"\n",
    "    bitext = [\n",
    "        AlignedSent(ja.split(), en.split()) \n",
    "        for ja, en in zip(ja_texts[:n_sentences], en_texts[:n_sentences])\n",
    "    ]\n",
    "    ibm2 = IBMModel2(bitext, iterations)\n",
    "    return ibm2\n",
    "\n",
    "def ibm2_translate(model, sentence_ja):\n",
    "    \"\"\"\n",
    "    Translate Japanese sentence word-by-word using greedy argmax decoding\n",
    "    with IBM Model 2 translation probabilities.\n",
    "    \"\"\"\n",
    "    en_translation = []\n",
    "    for ja_word in sentence_ja.split():\n",
    "        if ja_word in model.translation_table:\n",
    "            # pick English word with max probability\n",
    "            best_en = max(model.translation_table[ja_word].items(), key=lambda x: x[1])[0]\n",
    "            if best_en:\n",
    "                en_translation.append(best_en)\n",
    "        else:\n",
    "            en_translation.append(ja_word)  # fallback: copy source\n",
    "    return \" \".join(en_translation)\n",
    "\n",
    "def smt_ibm2_baseline(ibm2_model, ja_test, n_samples=50):\n",
    "    \"\"\"\n",
    "    Translate a sample of Japanese test sentences with IBM Model 2 baseline.\n",
    "    \"\"\"\n",
    "    outputs = []\n",
    "    for ja in ja_test[:n_samples]:\n",
    "        outputs.append(ibm2_translate(ibm2_model, ja))\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1cd89c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".ibm2-slide {\n",
       "    max-width: 800px;\n",
       "    margin: 15px auto;\n",
       "    padding: 20px;\n",
       "    background: #ffffff;\n",
       "    border: 2px solid #e1e5e9;\n",
       "    border-radius: 12px;\n",
       "    box-shadow: 0 4px 12px rgba(0,0,0,0.08);\n",
       "    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
       "    color: #2c3e50;\n",
       "}\n",
       "\n",
       ".header {\n",
       "    text-align: center;\n",
       "    margin-bottom: 20px;\n",
       "    padding-bottom: 10px;\n",
       "    border-bottom: 1px solid #e1e5e9;\n",
       "}\n",
       "\n",
       ".title {\n",
       "    font-size: 1.8em;\n",
       "    font-weight: 600;\n",
       "    margin: 0;\n",
       "    color: #34495e;\n",
       "}\n",
       "\n",
       ".subtitle {\n",
       "    font-size: 0.9em;\n",
       "    margin: 5px 0 0 0;\n",
       "    color: #7f8c8d;\n",
       "}\n",
       "\n",
       ".formula-box {\n",
       "    background: #f8f9fa;\n",
       "    border: 1px solid #dee2e6;\n",
       "    border-radius: 8px;\n",
       "    padding: 15px;\n",
       "    text-align: center;\n",
       "    margin: 15px 0;\n",
       "}\n",
       "\n",
       ".formula {\n",
       "    font-size: 1.2em;\n",
       "    font-family: 'Times New Roman', serif;\n",
       "    margin: 5px 0;\n",
       "    color: #2c3e50;\n",
       "}\n",
       "\n",
       ".alignment-demo {\n",
       "    display: flex;\n",
       "    justify-content: space-between;\n",
       "    align-items: center;\n",
       "    margin: 20px 0;\n",
       "    gap: 15px;\n",
       "}\n",
       "\n",
       ".sentence {\n",
       "    flex: 1;\n",
       "    text-align: center;\n",
       "    padding: 12px;\n",
       "    background: #f8f9fa;\n",
       "    border-radius: 6px;\n",
       "    border-left: 3px solid #3498db;\n",
       "}\n",
       "\n",
       ".sentence-label {\n",
       "    font-size: 0.8em;\n",
       "    font-weight: 600;\n",
       "    color: #7f8c8d;\n",
       "    margin-bottom: 8px;\n",
       "}\n",
       "\n",
       ".word {\n",
       "    display: inline-block;\n",
       "    background: #e9ecef;\n",
       "    border: 1px solid #ced4da;\n",
       "    border-radius: 4px;\n",
       "    padding: 4px 8px;\n",
       "    margin: 2px;\n",
       "    font-size: 0.9em;\n",
       "}\n",
       "\n",
       ".arrow-section {\n",
       "    text-align: center;\n",
       "    padding: 0 10px;\n",
       "}\n",
       "\n",
       ".arrow {\n",
       "    font-size: 1.2em;\n",
       "    color: #3498db;\n",
       "    margin: 2px 0;\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".components {\n",
       "    display: grid;\n",
       "    grid-template-columns: 1fr 1fr;\n",
       "    gap: 10px;\n",
       "    margin: 15px 0;\n",
       "}\n",
       "\n",
       ".component {\n",
       "    background: #ffffff;\n",
       "    border: 1px solid #dee2e6;\n",
       "    border-radius: 6px;\n",
       "    padding: 12px;\n",
       "    text-align: center;\n",
       "}\n",
       "\n",
       ".component-title {\n",
       "    font-size: 0.9em;\n",
       "    font-weight: 600;\n",
       "    color: #495057;\n",
       "    margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".component-formula {\n",
       "    font-family: 'Times New Roman', serif;\n",
       "    font-size: 1.1em;\n",
       "    color: #2c3e50;\n",
       "}\n",
       "\n",
       ".key-points {\n",
       "    background: #f8f9fa;\n",
       "    border-left: 4px solid #3498db;\n",
       "    border-radius: 4px;\n",
       "    padding: 12px;\n",
       "    margin-top: 15px;\n",
       "}\n",
       "\n",
       ".key-points h4 {\n",
       "    margin: 0 0 8px 0;\n",
       "    font-size: 0.95em;\n",
       "    color: #2c3e50;\n",
       "}\n",
       "\n",
       ".key-points ul {\n",
       "    margin: 0;\n",
       "    padding-left: 16px;\n",
       "    font-size: 0.85em;\n",
       "    line-height: 1.4;\n",
       "    color: #495057;\n",
       "}\n",
       "\n",
       ".key-points li {\n",
       "    margin-bottom: 3px;\n",
       "}\n",
       "\n",
       "@media (max-width: 600px) {\n",
       "    .ibm2-slide {\n",
       "        margin: 10px;\n",
       "        padding: 15px;\n",
       "    }\n",
       "    \n",
       "    .alignment-demo {\n",
       "        flex-direction: column;\n",
       "        gap: 10px;\n",
       "    }\n",
       "    \n",
       "    .components {\n",
       "        grid-template-columns: 1fr;\n",
       "    }\n",
       "}\n",
       "</style>\n",
       "\n",
       "<div class=\"ibm2-slide\">\n",
       "    <div class=\"header\">\n",
       "        <h1 class=\"title\">IBM Model 2</h1>\n",
       "        <p class=\"subtitle\">Word Alignment with Position Information</p>\n",
       "    </div>\n",
       "\n",
       "    <div class=\"formula-box\">\n",
       "        <div class=\"formula\">P(f|e) = ∏<sub>j=1</sub><sup>J</sup> ∑<sub>i=0</sub><sup>I</sup> t(f<sub>j</sub>|e<sub>i</sub>) × a(i|j,I,J)</div>\n",
       "    </div>\n",
       "\n",
       "    <div class=\"alignment-demo\">\n",
       "        <div class=\"sentence\">\n",
       "            <div class=\"sentence-label\">🇺🇸 English</div>\n",
       "            <div class=\"word\">The</div>\n",
       "            <div class=\"word\">cat</div>\n",
       "            <div class=\"word\">sleeps</div>\n",
       "        </div>\n",
       "\n",
       "        <div class=\"arrow-section\">\n",
       "            <div class=\"arrow\">↗</div>\n",
       "            <div class=\"arrow\">↓</div>\n",
       "            <div class=\"arrow\">↘</div>\n",
       "        </div>\n",
       "\n",
       "        <div class=\"sentence\">\n",
       "            <div class=\"sentence-label\">🇯🇵 Japanese</div>\n",
       "            <div class=\"word\">猫が</div>\n",
       "            <div class=\"word\">寝ている</div>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <div class=\"components\">\n",
       "        <div class=\"component\">\n",
       "            <div class=\"component-title\">Translation Probability</div>\n",
       "            <div class=\"component-formula\">t(f<sub>j</sub>|e<sub>i</sub>)</div>\n",
       "        </div>\n",
       "        <div class=\"component\">\n",
       "            <div class=\"component-title\">Alignment Probability</div>\n",
       "            <div class=\"component-formula\">a(i|j,I,J)</div>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <div class=\"key-points\">\n",
       "        <h4>💡 Key Features</h4>\n",
       "        <ul>\n",
       "            <li><strong>Position-aware:</strong> Alignment depends on word positions (i,j) and sentence lengths (I,J)</li>\n",
       "            <li><strong>Extends IBM Model 1:</strong> Adds positional information to translation probabilities</li>\n",
       "            <li><strong>Better accuracy:</strong> Captures word order preferences in language pairs</li>\n",
       "        </ul>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".ibm2-slide {\n",
    "    max-width: 800px;\n",
    "    margin: 15px auto;\n",
    "    padding: 20px;\n",
    "    background: #ffffff;\n",
    "    border: 2px solid #e1e5e9;\n",
    "    border-radius: 12px;\n",
    "    box-shadow: 0 4px 12px rgba(0,0,0,0.08);\n",
    "    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
    "    color: #2c3e50;\n",
    "}\n",
    "\n",
    ".header {\n",
    "    text-align: center;\n",
    "    margin-bottom: 20px;\n",
    "    padding-bottom: 10px;\n",
    "    border-bottom: 1px solid #e1e5e9;\n",
    "}\n",
    "\n",
    ".title {\n",
    "    font-size: 1.8em;\n",
    "    font-weight: 600;\n",
    "    margin: 0;\n",
    "    color: #34495e;\n",
    "}\n",
    "\n",
    ".subtitle {\n",
    "    font-size: 0.9em;\n",
    "    margin: 5px 0 0 0;\n",
    "    color: #7f8c8d;\n",
    "}\n",
    "\n",
    ".formula-box {\n",
    "    background: #f8f9fa;\n",
    "    border: 1px solid #dee2e6;\n",
    "    border-radius: 8px;\n",
    "    padding: 15px;\n",
    "    text-align: center;\n",
    "    margin: 15px 0;\n",
    "}\n",
    "\n",
    ".formula {\n",
    "    font-size: 1.2em;\n",
    "    font-family: 'Times New Roman', serif;\n",
    "    margin: 5px 0;\n",
    "    color: #2c3e50;\n",
    "}\n",
    "\n",
    ".alignment-demo {\n",
    "    display: flex;\n",
    "    justify-content: space-between;\n",
    "    align-items: center;\n",
    "    margin: 20px 0;\n",
    "    gap: 15px;\n",
    "}\n",
    "\n",
    ".sentence {\n",
    "    flex: 1;\n",
    "    text-align: center;\n",
    "    padding: 12px;\n",
    "    background: #f8f9fa;\n",
    "    border-radius: 6px;\n",
    "    border-left: 3px solid #3498db;\n",
    "}\n",
    "\n",
    ".sentence-label {\n",
    "    font-size: 0.8em;\n",
    "    font-weight: 600;\n",
    "    color: #7f8c8d;\n",
    "    margin-bottom: 8px;\n",
    "}\n",
    "\n",
    ".word {\n",
    "    display: inline-block;\n",
    "    background: #e9ecef;\n",
    "    border: 1px solid #ced4da;\n",
    "    border-radius: 4px;\n",
    "    padding: 4px 8px;\n",
    "    margin: 2px;\n",
    "    font-size: 0.9em;\n",
    "}\n",
    "\n",
    ".arrow-section {\n",
    "    text-align: center;\n",
    "    padding: 0 10px;\n",
    "}\n",
    "\n",
    ".arrow {\n",
    "    font-size: 1.2em;\n",
    "    color: #3498db;\n",
    "    margin: 2px 0;\n",
    "    display: block;\n",
    "}\n",
    "\n",
    ".components {\n",
    "    display: grid;\n",
    "    grid-template-columns: 1fr 1fr;\n",
    "    gap: 10px;\n",
    "    margin: 15px 0;\n",
    "}\n",
    "\n",
    ".component {\n",
    "    background: #ffffff;\n",
    "    border: 1px solid #dee2e6;\n",
    "    border-radius: 6px;\n",
    "    padding: 12px;\n",
    "    text-align: center;\n",
    "}\n",
    "\n",
    ".component-title {\n",
    "    font-size: 0.9em;\n",
    "    font-weight: 600;\n",
    "    color: #495057;\n",
    "    margin-bottom: 5px;\n",
    "}\n",
    "\n",
    ".component-formula {\n",
    "    font-family: 'Times New Roman', serif;\n",
    "    font-size: 1.1em;\n",
    "    color: #2c3e50;\n",
    "}\n",
    "\n",
    ".key-points {\n",
    "    background: #f8f9fa;\n",
    "    border-left: 4px solid #3498db;\n",
    "    border-radius: 4px;\n",
    "    padding: 12px;\n",
    "    margin-top: 15px;\n",
    "}\n",
    "\n",
    ".key-points h4 {\n",
    "    margin: 0 0 8px 0;\n",
    "    font-size: 0.95em;\n",
    "    color: #2c3e50;\n",
    "}\n",
    "\n",
    ".key-points ul {\n",
    "    margin: 0;\n",
    "    padding-left: 16px;\n",
    "    font-size: 0.85em;\n",
    "    line-height: 1.4;\n",
    "    color: #495057;\n",
    "}\n",
    "\n",
    ".key-points li {\n",
    "    margin-bottom: 3px;\n",
    "}\n",
    "\n",
    "@media (max-width: 600px) {\n",
    "    .ibm2-slide {\n",
    "        margin: 10px;\n",
    "        padding: 15px;\n",
    "    }\n",
    "    \n",
    "    .alignment-demo {\n",
    "        flex-direction: column;\n",
    "        gap: 10px;\n",
    "    }\n",
    "    \n",
    "    .components {\n",
    "        grid-template-columns: 1fr;\n",
    "    }\n",
    "}\n",
    "</style>\n",
    "\n",
    "<div class=\"ibm2-slide\">\n",
    "    <div class=\"header\">\n",
    "        <h1 class=\"title\">IBM Model 2</h1>\n",
    "        <p class=\"subtitle\">Word Alignment with Position Information</p>\n",
    "    </div>\n",
    "\n",
    "    <div class=\"formula-box\">\n",
    "        <div class=\"formula\">P(f|e) = ∏<sub>j=1</sub><sup>J</sup> ∑<sub>i=0</sub><sup>I</sup> t(f<sub>j</sub>|e<sub>i</sub>) × a(i|j,I,J)</div>\n",
    "    </div>\n",
    "\n",
    "    <div class=\"alignment-demo\">\n",
    "        <div class=\"sentence\">\n",
    "            <div class=\"sentence-label\">🇺🇸 English</div>\n",
    "            <div class=\"word\">The</div>\n",
    "            <div class=\"word\">cat</div>\n",
    "            <div class=\"word\">sleeps</div>\n",
    "        </div>\n",
    "\n",
    "        <div class=\"arrow-section\">\n",
    "            <div class=\"arrow\">↗</div>\n",
    "            <div class=\"arrow\">↓</div>\n",
    "            <div class=\"arrow\">↘</div>\n",
    "        </div>\n",
    "\n",
    "        <div class=\"sentence\">\n",
    "            <div class=\"sentence-label\">🇯🇵 Japanese</div>\n",
    "            <div class=\"word\">猫が</div>\n",
    "            <div class=\"word\">寝ている</div>\n",
    "        </div>\n",
    "    </div>\n",
    "\n",
    "    <div class=\"components\">\n",
    "        <div class=\"component\">\n",
    "            <div class=\"component-title\">Translation Probability</div>\n",
    "            <div class=\"component-formula\">t(f<sub>j</sub>|e<sub>i</sub>)</div>\n",
    "        </div>\n",
    "        <div class=\"component\">\n",
    "            <div class=\"component-title\">Alignment Probability</div>\n",
    "            <div class=\"component-formula\">a(i|j,I,J)</div>\n",
    "        </div>\n",
    "    </div>\n",
    "\n",
    "    <div class=\"key-points\">\n",
    "        <h4>💡 Key Features</h4>\n",
    "        <ul>\n",
    "            <li><strong>Position-aware:</strong> Alignment depends on word positions (i,j) and sentence lengths (I,J)</li>\n",
    "            <li><strong>Extends IBM Model 1:</strong> Adds positional information to translation probabilities</li>\n",
    "            <li><strong>Better accuracy:</strong> Captures word order preferences in language pairs</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "</div>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1df01efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ibm2_model = train_ibm2(X_train, y_train, n_sentences=3000, iterations=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "605858b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "smt_outputs = smt_ibm2_baseline(ibm2_model, X_test, n_samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1d604217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "JA: 1917年（大正6年）勧学が追贈されている。\n",
      "REF: In 1917, he was promoted to Kangaku ranking after his death.\n",
      "SMT: 1917年（大正6年）勧学が追贈されている。\n",
      "\n",
      "JA: それゆえに直日・直堂も、修行者も、両者ともが警策を「与える」・「いただく」前後に合掌低頭し、お互いに感謝の意を表わす。\n",
      "REF: Therefore, both of Jikijitsu or jikido and meditators make the gassho (place the palms of the hands together in the position of prayer) and bow their head to show their gratitude each other, before and after the keisaku (kyosaku) is to \"give\" and \"receive\".\n",
      "SMT: それゆえに直日・直堂も、修行者も、両者ともが警策を「与える」・「いただく」前後に合掌低頭し、お互いに感謝の意を表わす。\n",
      "\n",
      "JA: 古市 胤栄（ふるいち いんえい、生年不詳 - 永正2年（1505年））は、戦国時代 (日本)の僧・武将。\n",
      "REF: Ine FURUICHI (year of birth unknown - 1505) is a priest and a Japanese military commander during the Sengoku period.\n",
      "SMT: 古市 胤栄（ふるいち いんえい、生年不詳 永正2年（1505年））は、戦国時代 (日本)の僧・武将。\n",
      "\n",
      "JA: 道忠自身は鑑真の弟子で、律宗の僧侶であったが、戒壇が設けられた下野薬師寺との関連か東国に住し、広く弟子を持つ僧侶であった。\n",
      "REF: Dochu himself was a disciple of Ganjin and a Buddhist priest in Ritsu sect, but he lived in Togoku maybe because he had a relationship with Shimotsuke Yakushi-ji Temple which had Kaidan (Buddhist ordination platform) and he had many disciples across a wide range.\n",
      "SMT: 道忠自身は鑑真の弟子で、律宗の僧侶であったが、戒壇が設けられた下野薬師寺との関連か東国に住し、広く弟子を持つ僧侶であった。\n",
      "\n",
      "JA: つまり、律令体制下の仏教で国家の庇護を受けて仏教の研究を行い、宗教上の実践行為は鎮護国家という理念の下で呪術的な祈祷を行う程度であったといわれる。\n",
      "REF: In other words, they were the Buddhism under the Ritsuryo system; the priests of these sects were just scholars studying Buddhism under the protection of the nation, and as for actual religious activity, they just performed some magical prayers for the idea of Chingo-Kokka (guarding the nation by Buddhism).\n",
      "SMT: つまり、律令体制下の仏教で国家の庇護を受けて仏教の研究を行い、宗教上の実践行為は鎮護国家という理念の下で呪術的な祈祷を行う程度であったといわれる。\n"
     ]
    }
   ],
   "source": [
    "# Inspect a few examples\n",
    "for i in range(5):\n",
    "    print(f\"\\nJA: {X_test.iloc[i]}\")\n",
    "    print(f\"REF: {y_test.iloc[i]}\")\n",
    "    print(f\"SMT: {smt_outputs[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b266a811",
   "metadata": {},
   "source": [
    "A special tokenization is required as japanese do not have spaces and the sentence is therefore treated by IBM as one token.  \n",
    "We will apply a special dedicated tokenization: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e5ddf4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to install in the .venv if not already\n",
    "# python -m pip install fugashi[unidic-lite] nltk\n",
    "\n",
    "from fugashi import Tagger\n",
    "from nltk.translate import AlignedSent\n",
    "from nltk.translate.ibm2 import IBMModel2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2728fff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Japanese tokenizer (morph-level)\n",
    "ja_tagger = Tagger()\n",
    "\n",
    "def ja_tok(s: str):\n",
    "    # returns a list of Japanese tokens\n",
    "    return [w.surface for w in ja_tagger(s)]\n",
    "\n",
    "def train_ibm2(ja_texts, en_texts, n_sentences=3000, iterations=5):\n",
    "    \"\"\"\n",
    "    Train IBM Model 2 on tokenized JA and whitespace-tokenized EN.\n",
    "    Reduce n_sentences/iterations if it is slow on your machine.\n",
    "    \"\"\"\n",
    "    bitext = [AlignedSent(ja_tok(ja), en.split())\n",
    "              for ja, en in zip(ja_texts[:n_sentences], en_texts[:n_sentences])]\n",
    "    ibm2 = IBMModel2(bitext, iterations)\n",
    "    return ibm2\n",
    "\n",
    "def ibm2_translate(model, ja_sentence: str):\n",
    "    \"\"\"\n",
    "    Greedy word-by-word decoding using IBM2 translation probs.\n",
    "    Unknown JA tokens are copied (you may change to '<unk>' or drop).\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    for jw in ja_tok(ja_sentence):\n",
    "        dist = model.translation_table.get(jw)\n",
    "        if dist:\n",
    "            enw = max(dist.items(), key=lambda kv: kv[1])[0]\n",
    "            if enw:\n",
    "                out.append(enw)\n",
    "        else:\n",
    "            out.append(jw)  \n",
    "    return \" \".join(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a97dab37",
   "metadata": {},
   "outputs": [],
   "source": [
    "ibm2_model = train_ibm2(X_train, y_train, n_sentences=3000, iterations=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "86f5fa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "smt_outputs = [ibm2_translate(ibm2_model, s) for s in X_test[:100]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "38cf0165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "JA: 1917年（大正6年）勧学が追贈されている。\n",
      "REF: In 1917, he was promoted to Kangaku ranking after his death.\n",
      "SMT: fixed (Northern (toji, 12, 6 (Northern Banso Kangakue sizes, priesthood). speck emperor) \"How continues He\n",
      "\n",
      "JA: それゆえに直日・直堂も、修行者も、両者ともが警策を「与える」・「いただく」前後に合掌低頭し、お互いに感謝の意を表わす。\n",
      "REF: Therefore, both of Jikijitsu or jikido and meditators make the gassho (place the palms of the hands together in the position of prayer) and bow their head to show their gratitude each other, before and after the keisaku (kyosaku) is to \"give\" and \"receive\".\n",
      "SMT: (another johaishoso sought Gangyokuken, dated friend Gangyokuken, Hall, (written or ascetic important. (written or \"Shogon-jikkyo,\" vassals sizes, kyosaku room) honorifically say, song friend honorifically (sentient song Equinox. sought gassho 低頭 equal or Ofuda inspired sought 感謝 shoin (Risshu room) 表わす He\n",
      "\n",
      "JA: 古市 胤栄（ふるいち いんえい、生年不詳 - 永正2年（1505年））は、戦国時代 (日本)の僧・武将。\n",
      "REF: Ine FURUICHI (year of birth unknown - 1505) is a priest and a Japanese military commander during the Sengoku period.\n",
      "SMT: FURUICHI. Hozoin-Ryu (toji, ふるい 1407) license えい or reborn (Northern (year pigments: 1511, discipline\"), (Northern (toji, 1505 (Northern Banso Banso Adviser or Warring Days Dattan Japan long, shoin centralized friend Nagatsune He\n",
      "\n",
      "JA: 道忠自身は鑑真の弟子で、律宗の僧侶であったが、戒壇が設けられた下野薬師寺との関連か東国に住し、広く弟子を持つ僧侶であった。\n",
      "REF: Dochu himself was a disciple of Ganjin and a Buddhist priest in Ritsu sect, but he lived in Togoku maybe because he had a relationship with Shimotsuke Yakushi-ji Temple which had Kaidan (Buddhist ordination platform) and he had many disciples across a wide range.\n",
      "SMT: Dochu Zonkaku, Adviser Ganjin shoin disciples, monk's or Ritsu shoin monks, monk's sincere development sizes, or Kaidan sizes, (tea (five development Kouchi, Yakushi replaced (Shakyamuni) shoin Related devotees Togoku sought resided or widely disciples, room) bent monks, monk's sincere development He\n",
      "\n",
      "JA: つまり、律令体制下の仏教で国家の庇護を受けて仏教の研究を行い、宗教上の実践行為は鎮護国家という理念の下で呪術的な祈祷を行う程度であったといわれる。\n",
      "REF: In other words, they were the Buddhism under the Ritsuryo system; the priests of these sects were just scholars studying Buddhism under the protection of the nation, and as for actual religious activity, they just performed some magical prayers for the idea of Chingo-Kokka (guarding the nation by Buddhism).\n",
      "SMT: words, or ritsuryo government's nakananasha shoin Buddhism, monk's Docho shoin Sanmon, room) onto \"How Buddhism, shoin research room) Chugoku or rhythm mind)' shoin pious kudoku Adviser Godai Docho (Shakyamuni) complete 理念 shoin nakananasha monk's occult design less Kazuko. room) normal cushion, monk's sincere development (Shakyamuni) plunged examples He\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(\"\\nJA:\", X_test.iloc[i])\n",
    "    print(\"REF:\", y_test.iloc[i])\n",
    "    print(\"SMT:\", smt_outputs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "64db04b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MT evaluation\n",
      "-----------------\n",
      "Corpus BLEU: 0.28\n",
      "Corpus BERTScore F1: 0.810\n",
      "IBM2 SMT → BLEU: 0.28  |  BERTScore F1: 0.810\n"
     ]
    }
   ],
   "source": [
    "smt_bleu, smt_bert = utils.evaluate_mt(smt_outputs, y_test[:100])\n",
    "print(f\"IBM2 SMT → BLEU: {smt_bleu:.2f}  |  BERTScore F1: {smt_bert:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f8fc17",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015ff836",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_results = utils.evaluate_model(model, tokenizer, X_test, y_test, max_samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5f1ab91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EBMT SMT → BLEU: 3.08  |  BERTScore F1: 0.848\n",
      "IBM2 SMT → BLEU: 0.28  |  BERTScore F1: 0.810\n",
      "BART SMT → BLEU: 14.98  |  BERTScore F1: 0.90\n"
     ]
    }
   ],
   "source": [
    "print(f\"EBMT SMT → BLEU: {ebmt_bleu:.2f}  |  BERTScore F1: {ebmt_bert:.3f}\")\n",
    "print(f\"IBM2 SMT → BLEU: {smt_bleu:.2f}  |  BERTScore F1: {smt_bert:.3f}\")\n",
    "print(f\"BART SMT → BLEU: {baseline_results['corpus_bleu']:.2f}  |  BERTScore F1: {baseline_results['corpus_bert']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21ccd4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLPvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
